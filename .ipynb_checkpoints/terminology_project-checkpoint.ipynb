{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology - Project\n",
    "Authors: Cécile MACAIRE & Ludivine ROBERT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "spacy_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from lexicon\n",
    "def read_data(file):\n",
    "    \"\"\"Read data file with pandas dataframe\"\"\"\n",
    "    return pd.read_csv(file, sep='\\t')\n",
    "\n",
    "def select_data(dataframe):\n",
    "    \"\"\"Lemmatization of lexicon with scapy\"\"\"\n",
    "    terms = dataframe['pilot']\n",
    "    lemma = []\n",
    "    for el in terms:\n",
    "        doc = spacy_nlp(el.lower())\n",
    "        tmp = [token.lemma_ for token in doc]\n",
    "        lemma = [l.replace(' - ', '-') for l in lemma]\n",
    "        lemma.append(' '.join(tmp))\n",
    "    df = pd.DataFrame({'pattern':dataframe['pattern'], 'pilot':dataframe['pilot'], 'lemma':lemma})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text\n",
    "def read_file(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return f.read()\n",
    "        \n",
    "def lemma_posttag(file):\n",
    "    \"\"\"Convert post-tag scapy into corresponding pattern from lexicon\"\"\"\n",
    "    text = read_file(file)\n",
    "    doc_a = spacy_nlp(text)\n",
    "    doc = spacy_nlp(text.lower())\n",
    "    new_pos = []\n",
    "    pos = []\n",
    "    lemma = []\n",
    "    t = []\n",
    "    original = [token.text for token in doc_a]\n",
    "    for token in doc:\n",
    "        t.append(token.text)\n",
    "        lemma.append(token.lemma_)\n",
    "        pos.append(token.pos_)\n",
    "        if token.pos_ == 'NOUN' or token.pos_ == 'PROPN':\n",
    "            new_pos.append('N')\n",
    "        elif token.pos_ == 'VERB':\n",
    "            new_pos.append('V')\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            new_pos.append('A')\n",
    "        elif token.pos_ == 'CCONJ' or token.pos_ == 'SCONJ':\n",
    "            new_pos.append('C')\n",
    "        elif token.pos_ == 'PART' or token.pos_ == 'ADP':\n",
    "            new_pos.append('P')\n",
    "        else:\n",
    "            new_pos.append('')\n",
    "#     print(len(original))\n",
    "#     print(len(lemma))\n",
    "#     print(len(t))\n",
    "#     print(len(pos))\n",
    "#     print(len(new_pos))\n",
    "    frame = pd.DataFrame({'tokens': original,'tokens_lower':t, 'lemma':lemma, 'pos':pos, 'pattern':new_pos})\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_adj = ['acoustic', 'accented', 'artificial', 'attentional', 'autoregressive', 'bidirectional', 'bilingual', 'cross-lingual', 'fluent',\n",
    "            'gated', 'generated', 'intelligible', 'labelled', 'phonetic', 'monolingual', 'multilingual', 'multispeaker', 'neural',\n",
    "            'substantial', 'supervised', 'training', 'unlabelled', 'unsupervised']\n",
    "def rules(terms_dataframe, text_dataframe):\n",
    "    \"\"\"Define rules from terms according to their pattern\"\"\"\n",
    "    new_terms = []\n",
    "    for terms in terms_dataframe['lemma']:\n",
    "        # Get the same structure of terms as in text dataframe\n",
    "        tmp = ' '.join(terms.split('-'))\n",
    "        new_terms.append(tmp.split(' '))\n",
    "    for i, token in enumerate(text_dataframe['lemma']):\n",
    "        for j, t in enumerate(new_terms):\n",
    "            # Case 1: term of size 3 seperated by dashes (ex: text-to-speech) and followed by 1, 2 Nouns or 1 Adj and 1 Noun is a term \n",
    "            if len(t) == 3 and len(text_dataframe['lemma']) >= i+5:\n",
    "                if token == t[0] and text_dataframe['lemma'][i+1] == '-' and (text_dataframe['lemma'][i+2] == 'to' or text_dataframe['lemma'][i+2] == 'of' or text_dataframe['lemma'][i+2] == 'by' or text_dataframe['pattern'][i+2] == 'N') and text_dataframe['lemma'][i+3] == '-' and text_dataframe['lemma'][i+4] == t[2]:\n",
    "                    # followed by 2 nouns (ex: text-to-speech modal synthesis)\n",
    "                    if (text_dataframe['pattern'][i+5] == 'N' or text_dataframe['pattern'][i+4] == 'A') and text_dataframe['pattern'][i+6] == 'N':\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+6] = text_dataframe['tokens'][i+6]+']'                        \n",
    "                    elif text_dataframe['pattern'][i+5] == 'N':\n",
    "                        # followed by 1 noun (ex: text-to-speech system)\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+5] = text_dataframe['tokens'][i+5]+']'\n",
    "                    else:\n",
    "                        text_dataframe['tokens'][i] = '[' + text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i + 4] = text_dataframe['tokens'][i + 4] + ']'\n",
    "            # Case 2: term of size 2 separated by dashes (ex: encoder-decoder) and followed by 0,1,2 or 3 nouns is a term\n",
    "            elif len(t) >= 2 and len(text_dataframe['lemma']) >= i+3 and i != 0:\n",
    "                if token == 'front' and text_dataframe['lemma'][i+1] == '-' and text_dataframe['lemma'][i+2] == 'end':\n",
    "                    if text_dataframe['pattern'][i-1] == 'N':\n",
    "                        text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]\n",
    "                        text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "                if token == t[0] and text_dataframe['lemma'][i+1] == '-' and text_dataframe['lemma'][i+2] == t[1]:\n",
    "                    # followed by 3 nouns (ex: HMM-based generation synthesis approach)\n",
    "                    if text_dataframe['pattern'][i+3] == 'N' and text_dataframe['pattern'][i+4] == 'N' and text_dataframe['pattern'][i+5] == 'N':\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+5] = text_dataframe['tokens'][i+5]+']'\n",
    "                    # followed by 2 nouns (ex: HMM-based generation synthesis)\n",
    "                    elif (text_dataframe['pattern'][i+3] == 'N' or text_dataframe['pattern'][i+3] == 'A' or text_dataframe['pattern'][i + 3] == 'V') and text_dataframe['pattern'][i+4] == 'N':\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+4] = text_dataframe['tokens'][i+4]+']'\n",
    "                    # followed by 1 noun (ex: cross-lingual adaptation)\n",
    "                    elif text_dataframe['pattern'][i+3] == 'N':\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+3] = text_dataframe['tokens'][i+3]+']'\n",
    "                    # followed by nothing (ex: mel-spectrogram)\n",
    "                    else:\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "        if (token == 'data' or token == 'voice' or token == 'datum' or token == 'speaker' or token == 'dataset' or token == 'database' or token == 'feature' or token == 'corpus' or token == 'language') and i != 0 and len(text_dataframe['lemma']) >= i+1:\n",
    "            if text_dataframe['pattern'][i-1] == 'N' or text_dataframe['pattern'][i-1] == 'A':\n",
    "                text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]\n",
    "                text_dataframe['tokens'][i] = text_dataframe['tokens'][i]+']'\n",
    "            elif text_dataframe['pattern'][i+1] == 'N':\n",
    "                text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                text_dataframe['tokens'][i+1] = text_dataframe['tokens'][i+1]+']'\n",
    "        if i != 0:\n",
    "            if text_dataframe['lemma'][i-1] in rule_adj and '[' in text_dataframe['tokens'][i]:\n",
    "                text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]+']'\n",
    "            elif i >= 3 and text_dataframe['lemma'][i-1] in rule_adj and text_dataframe['lemma'][i-3] == 'non' and '[' in text_dataframe['tokens'][i]:\n",
    "                    text_dataframe['tokens'][i-3] = '['+text_dataframe['tokens'][i-3]\n",
    "                    text_dataframe['tokens'][i-3] = text_dataframe['tokens'][i-1] + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_4 = ['accent', 'accuracy', 'activation', 'adaptation', 'algorithm', 'alignment', 'approach', \n",
    "          'architecture', 'attribute', 'boundary', 'cell', 'class', 'classifier', 'cluster', 'component', \n",
    "          'concatenation', 'content', 'contour', 'control', 'conversion', 'coverage', 'detection', \n",
    "          'detection', 'device', 'dictionary', 'embedding', 'encoding', 'engineering', 'entry', 'error', \n",
    "          'evaluation', 'experiment', 'expertise', 'file', 'filter', 'form', 'framework', 'function', \n",
    "          'generation', 'identification', 'implementation', 'improvement', 'inference', 'input', 'kernel', 'layer', 'learning', \n",
    "          'length', 'location', 'mapping', 'method', 'model', 'module', 'naturalness', 'network', \n",
    "          'nonlinearity', 'optimization', 'output', 'pair', 'parameter', 'pipeline', 'posterior', 'prediction', \n",
    "          'process', 'processing', 'quality', 'realization', 'recognition', 'representation', 'research', \n",
    "          'result', 'sample', 'score', 'sequence', 'set', 'setting', 'signal', 'string', 'study', 'symbol', \n",
    "          'synthesis', 'synthesizer', 'system', 'task', 'technique', 'technique', 'technology', 'token', 'tool', \n",
    "          'toolkit', 'training', 'transcription', 'transfer', 'transform', 'translation', 'value', 'generator',\n",
    "         'corpora', 'tilt', 'knowledge', 'category', 'track', 'tagger', 'unit']\n",
    "def annotate(terms_dataframe, text_dataframe):\n",
    "    \"\"\"Annotate the terms of the text thanks to list of terms + applied rules\"\"\"\n",
    "    rules(terms_dataframe, text_dataframe)  # apply rules\n",
    "    for i, token in enumerate(text_dataframe['lemma']):\n",
    "        for term in terms_dataframe['lemma']:\n",
    "            term = term.split(' ')\n",
    "            # Case 1: if terms of length 4, we check if each word from text corresponds to each word in the term\n",
    "            if len(term) == 4:\n",
    "                term_1 = term[0]\n",
    "                if token == term_1 and len(text_dataframe['lemma']) >= i+4:\n",
    "                    if text_dataframe['lemma'][i+1] == term[1] and text_dataframe['lemma'][i+2] == term[2] and text_dataframe['lemma'][i+3] == term[3]:\n",
    "                        if text_dataframe['lemma'][i+4] in rule_4:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+4] = text_dataframe['tokens'][i+4]+']'\n",
    "                        else:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+3] = text_dataframe['tokens'][i+3]+']'\n",
    "            # Case 2: terms of length 3\n",
    "            elif len(term) == 3:\n",
    "                term_1 = term[0]\n",
    "                if token == term_1 and len(text_dataframe['lemma']) > i+3:\n",
    "                    if text_dataframe['lemma'][i+1] == term[1] and text_dataframe['lemma'][i+2] == term[2]:\n",
    "                        if text_dataframe['lemma'][i+3] in rule_4:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+3] = text_dataframe['tokens'][i+3]+']'\n",
    "                        else:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "            # Case 3: terms of length 2\n",
    "            elif len(term) == 2:\n",
    "                if token == term[0] and len(text_dataframe['lemma']) > i+2:\n",
    "                    if text_dataframe['lemma'][i+1] == term[1]:\n",
    "                        if text_dataframe['lemma'][i+2] in rule_4:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "                        else:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+1] = text_dataframe['tokens'][i+1]+']'\n",
    "            # Case 4: term of length 1\n",
    "            elif token == term[0] and i > 1 and text_dataframe['lemma'][i-1] == 'of' and text_dataframe['lemma'][i-2] == 'sequence':\n",
    "                text_dataframe['tokens'][i-2] = '['+text_dataframe['tokens'][i-2]\n",
    "                text_dataframe['tokens'][i] = text_dataframe['tokens'][i]+']'\n",
    "            elif token == term[0] and len(term) == 1 and len(text_dataframe['lemma']) >= i+2 and text_dataframe['lemma'][i+1] == ')':\n",
    "                if text_dataframe['lemma'][i+2] in rule_4:\n",
    "                    text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]\n",
    "                    text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "                else:\n",
    "                    text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]+']'\n",
    "            elif token == term[0] and len(term) == 1 and len(text_dataframe['lemma']) >= i+1:\n",
    "                if text_dataframe['lemma'][i+1] in rule_4:\n",
    "                    text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                    text_dataframe['tokens'][i+1] = text_dataframe['tokens'][i+1]+']'\n",
    "                else:\n",
    "                    text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]+']'\n",
    "        if i != 0:\n",
    "            if text_dataframe['lemma'][i-1] in rule_adj and '[' in text_dataframe['tokens'][i]:\n",
    "                text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]+']'\n",
    "            elif i >= 3 and text_dataframe['lemma'][i-1] in rule_adj and text_dataframe['lemma'][i-3] == 'non' and '[' in text_dataframe['tokens'][i]:\n",
    "                text_dataframe['tokens'][i-3] = '['+text_dataframe['tokens'][i-3]\n",
    "                text_dataframe['tokens'][i-3] = text_dataframe['tokens'][i-1] + ']'\n",
    "    return text_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_annotated_text(text_dataframe):\n",
    "    \"\"\"Return the text from the annotated text dataframe with the correct annotation of brackets\"\"\"\n",
    "    content = ' '.join(text_dataframe['tokens'].to_list())\n",
    "    compt = 0\n",
    "    compt2 = 0\n",
    "    string = ''\n",
    "    for i in content:\n",
    "        if i == '[':\n",
    "            if compt == 0:\n",
    "                compt += 1\n",
    "                string += i\n",
    "            elif compt >= 1:\n",
    "                compt += 1\n",
    "        elif i == ']':\n",
    "            if compt-1 != compt2:\n",
    "                compt2 += 1\n",
    "            else:\n",
    "                string += i\n",
    "                compt = 0\n",
    "                compt2 = 0\n",
    "        else:\n",
    "            string += i\n",
    "    string2 = ''\n",
    "    string = string.replace('] [', ' ')\n",
    "    string = string.replace(' .', '.')\n",
    "    string = string.replace(' ’', '’')\n",
    "    string = string.replace(' ,', ',')\n",
    "    string = string.replace(' - ', '-')\n",
    "    string = string.replace('( ', '(')\n",
    "    string = string.replace(' )', ')')\n",
    "    string = string.replace(']-[', '-')\n",
    "    string = string.replace('.]', '].')\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATISTICAL PARAMETRIC SPEECH SYNTHESIS] \n",
      "\n",
      " ABSTRACT \n",
      "\n",
      " This paper gives a general overview of techniques in [statistical parametric speech synthesis]. \n",
      " One of the instances of these techniques, called [HMM-based generation synthesis] (or simply [HMM-based synthesis]), has recently been shown to be very effective in generating acceptable [speech synthesis]. \n",
      " This paper also contrasts these techniques with the more conventional [unit selection technology] that has dominated [speech synthesis] over the last ten years. Advantages and disadvantages of [statistical parametric synthesis] are highlighted as well as identifying where we expect the key developments to appear in the immediate future. \n",
      "\n",
      " Index Terms — [Speech synthesis], [hidden Markov models] \n",
      "\n",
      " BACKGROUND \n",
      "\n",
      " With the increase in power and resources of computer technology, building natural sounding [synthetic voices] has progressed from a knowledge-based activity to a data-based one. \n",
      " Rather than handcrafting each [phonetic] unit and its applicable contexts, high-quality [synthetic voices] may be built from sufficiently diverse [single speaker databases] of natural [speech]. \n",
      " We can see a progression from sxed inventories, found in diphone systems to the more general, but more resource consuming, techniques of [unit selection synthesis] where appropriate sub-word units are automatically selected from [large databases] of natural [speech]. \n",
      " ATR ν-talk was the srst to show the effectiveness of automatic selection of appropriate units, then CHATR generalized these techniques to [multiple languages] and an automatic training scheme. \n",
      " [Unit selection techniques] have risen to be the dominant synthesis technique. \n",
      " The quality of the output derives directly from the quality of the recordings, and it appears that the larger the database the better the coverage. \n",
      " Commercial systems have exploited these technique to bring us a new level of [synthetic speech]. \n",
      " However, although certainly successful, there is always the issue of spurious errors. \n",
      " When a desired sentence happens to require [phonetic] and [prosody] contexts that are under represented in a database, the quality of the synthesizer can be severely degraded. \n",
      " Even though this may be a rare event, a single bad join in an utterance can ruin the listeners ƀow. \n",
      " It is not possible to guarantee that bad joins and/or inappropriate units do not occur, simply because of the vast number of possible combinations that could occur. \n",
      " However for particular applications it is often possible to almost always avoid them. \n",
      " Limited domain synthesizers, where the database is designed for the particular application, go a long way to making almost all the synthetic output near perfect. \n",
      " However in spite of the desire for perfect synthesis all the time, there are limitations in the [unit selection technique]. \n",
      " No (or little) modiscation of the selected pieces of natural [speech] are carried out, thus limiting the output [speech] to the style of that in the original recordings. \n",
      " With a desire for more control over the [speech] variation, [larger databases] containing examples of different styles are required. \n",
      " IBM’s stylistic synthesis is a good example but is limited by the amount of variations that can be recorded. \n",
      " In direct contrast to this selecting of actual instances of [speech] from a database, [statistical parametric speech synthesis] has also grown in popularity over the last few years. \n",
      " [Statistical parametric synthesis] might be most simply described as generating the average of some set of similarly sounding [speech] segments. \n",
      " This contrasts directly with the desire in [unit selection] to keep the natural unmodised [speech] units, but using parametric models offers other benests. \n",
      " In both the [Blizzard Challenge] 2005 and 2006 where a common [speech database] is provided to participants to build a [synthetic voice], the results from listening tests have shown that one of the instances of [statistical parametric synthesis techniques] called [HMM-based generation synthesis] (or even [HMM-based synthesis]) offers more preferred (through [MOS] tests) and more understandable (through [WER scores]) synthesis. \n",
      " Although even the proponents of [statistical parametric synthesis] feel that the best examples of [unit selection] are better than the best examples of [statistical parametric synthesis], overall it appears that quality of [statistical parametric synthesis] has already reached a quality that can stand in its own right. \n",
      " The quality issue really comes down to the fact that given a parametric representation it is necessary to reconstruct the [speech] from those parameters. \n",
      " The reconstruction process is still not ideal. \n",
      " Although modeling the [spectral] and [prosody features] is relatively well desned, models of the residual / excitation are still yet to be fully developed, though composite models like STRAIGHT are proving to be useful. \n",
      " The following section gives a more formal desnition of [unit selection techniques] that will allow a easier contrast it to [statistical parametric synthesis]. \n",
      " Then [statistical parametric speech synthesis] is more formally desned, speciscally based on the implementation on the [HMM-based speech synthesis system] (HTS). \n",
      " The snal sections discuss some of the advantages in a [statistical parametric framework] highlighting some of the existing a future directions. \n",
      "\n",
      " [UNIT SELECTION SYNTHESIS] \n",
      "\n",
      " There seems to be two basic techniques in [unit selection], though they are theoretically not very different. \n",
      " Hunt and Black presented a selection model, which actually existed previously in ATR νtalk. \n",
      " The basic notion is that of a target cost, how well a candidate unit from the database matches the desired unit, and a concatenation cost which desnes how well two selected units combine. \n",
      " [Unit selection] requires the optimization of both these costs over the utterances. \n",
      " The desnition of target cost between a candidate unit u i and a desired unit, \n",
      " where j indexes over all features (typically [phonetic] and prosodic contexts are used). Concatenation cost is desned as... \n",
      "\n",
      " [STATISTICAL PARAMETRIC SYNTHESIS] \n",
      "\n",
      " Overview of a typical system \n",
      "\n",
      " Though in this case k may include [spectral] and [acoustic features]. \n",
      " Weights (w tj and w ck) have to be found for each feature, and actually implementations used a combination of trained and hand tuned weights. \n",
      " The second direction, use a clustering method that allows the target cost to effectively be precalculated. \n",
      " Units of the same type are clustered into a [decision tree] that asks questions about features available at synthesis time (e.g. [phonetic] and [prosody] context). \n",
      " All of these techniques depend on a acoustic distance measure which should be correlated with human perception. \n",
      " These apparently [unit selection] specisc issues are mentioned here because they have specisc counterparts in [statistical parametric synthesis]. \n",
      " Figure 1 is a block diagram of a typical [HMM-based speech synthesis system]. \n",
      " It consists of training and synthesis parts. \n",
      " The training part is similar to those used in [speech recognition systems]. \n",
      " The main difference is that both [spectrum] (e.g., [melcepstral] coefficients and their [dynamic features]) and excitation (e.g., log F 0 and its [dynamic features]) parameters are extracted from a [speech database] and modeled by context-dependent [HMMs] ([phonetic], linguistic, and prosodic contexts are taken into account). \n",
      " To model log F0 sequence which includes unvoiced regions properly, multi-space probability distributions are used for the state output stream for log F0. \n",
      " Each HMM has state duration densities to model the temporal structure of [speech]. \n",
      " As a result, the system models [spectrum], excitation, and durations in a unised framework. \n",
      " The synthesis part does the inverse operation of [speech recognition]. \n",
      " First, an arbitrarily given text corresponding an utterance to be synthesized is converted to a context-dependent [label sequence] and then the utterance HMM is constructed by concatenating the contextdependent [HMMs] according to the [label sequence]. \n",
      " Secondly, state durations of the HMM are determined based on the state duration [probability density functions]. \n",
      " Thirdly, the [speech parameter generation algorithm] (typically, case 1 in) generates the [sequence of mel-cepstral coefficients] and log F 0 values that maximize their output probabilities. \n",
      " Finally, a [speech waveform] is synthesized directly from the generated [mel-cepstral coefficients] and F0 values using the MLSA slter with binary pulse or noise excitation. \n",
      "\n",
      " Advantages and disadvantages \n",
      "\n",
      " The biggest disadvantage of the [HMM-based generation synthesis approach] against the [unit selection approach] is the quality of [synthesized speech]. \n",
      " There seems to be three factors which degrade the quality : [vocoder], modeling accuracy, and over-smoothing. \n",
      " The [synthesized speech] by the [HMM-based generation synthesis approach] sounds buzzy since it is based on the [vocoding technique]. \n",
      " To alleviate this problem, a high quality [vocoder] such as multi-band excitation scheme or STRAIGHT have been integrated. \n",
      " Several groups have recently applied LSP-type parameters instead of [mel-cepstral coefficients] to the [HMM-based generation synthesis approach]. \n",
      " The basic system uses ML-estimated [HMMs] as its [acoustic models]. \n",
      " Because this system generates [speech parameters] from its [acoustic models], model accuracy highly affects the quality of [synthesized speech]. \n",
      " To improve its modeling accuracy, a number of advanced [acoustic models] and training frameworks such as hidden semi-[Markov models] (HSMMs), trajectory [HMMs], buried [Markov models], trended [HMMs], stochastic [Markov] graphs, minimum generation error (MGE) criterion, and variational Bayesian approach have been investigated. \n",
      " In the basic system, the [speech parameter generation algorithm] is used to generate [spectral] and excitation parameters from [HMMs]. \n",
      " By taking account of constraints between the static and [dynamic features], it can generate smooth [speech parameter] trajectories. \n",
      " However, the generated [spectral] and excitation parameters are often over-smoothed. \n",
      " [Synthesized speech] using over-smoothed [spectral parameters] sounds muffled. \n",
      " To reduce this effect and enhance the [speech quality], postsltering, a conditional [speech parameter generation algorithm], or a [speech parameter generation algorithm] considering global variance have been used. \n",
      " Advantages of the [HMM-based generation synthesis approach] are \n",
      " 1) its [voice characteristics] can be easily modised, \n",
      " 2) it can be applied to [various languages] with little modiscation, \n",
      " 3) a variety of speaking styles or emotional [speech] can be synthesized using the small amount of [speech data], \n",
      " 4) techniques developed in [ASR] can be easily applied, \n",
      " 5) its footprint is relatively small. \n",
      " The [voice characteristics] in 1) can be changed by transforming HMM parameters appropriately because the system generates [speech waveforms] from the [HMMs] themselves. \n",
      " For example, either a [speaker adaptation], a [speaker interpolation], or an eigenvoice technique was applied to this system, and it was shown that the system could modify [voice characteristics]. \n",
      " Multilingual support in 2) can be easily realized because in this system only contextual factors are dependent on each language. \n",
      " Japanese, Mandarin, Korean, English, German, Portuguese, Swedish, Finnish, Slovenian, Croatian, Arabic, Farsi, and Polyglot systems have already been developed by various groups. \n",
      " Speaking styles and [emotional voices] in 3) can be constructed by re-estimating existing [average voice models] with only a few utterances using adaptation techniques. \n",
      " As for 4), we can employ a number of useful technologies developed for the [HMM-based speech recognition]. \n",
      " For example, structured precision matrix models, which can approximate full covariance models well using the small number of parameters, have successfully been applied to the system. \n",
      " Small footprints in 5) can be realized by storing statistics of [HMMs] rather than multi-templates of [speech] units. \n",
      " For example, footprints of the Nitech’s [Blizzard Challenge] 2005 voices were less than 2 MBytes with no compression. \n",
      "\n",
      " RELATION AND [HYBRID APPROACHES] \n",
      "\n",
      " Relation between two approaches \n",
      "\n",
      " Some of clustering-based [unit selection approaches] uses HMMbased state clustering. \n",
      " In this case, the structure is very similar to that of the [HMM-based generation synthesis approach]. \n",
      " The essential difference between the clustering-based [unit-selection approach] and the [HMM-based generation synthesis approach] is that each cluster in the generation approach is represented by statistics of the cluster instead of multi-templates of [speech] units. \n",
      " In the [HMM-based generation synthesis approach], distributions for [spectrum], F0, and duration are clustered independently. \n",
      " Accordingly, it has different [decision trees] for each of [spectrum], F0, and duration. \n",
      " On the other hand, [unit selection systems] often use regression trees (or [CART]) for [prosody prediction]. \n",
      " The [decision trees] for F 0 and duration in the [HMM-based generation synthesis approach] are essentially equivalent to the regression trees in the [unit selection systems]. \n",
      " However, in the [unit selection systems], leaves of one of trees must have [speech waveforms] : other trees are used to calculate target costs, to prune [waveform] candidates, or to give features for constructing the trees for [speech waveforms]. \n",
      " It is noted that in the [HMM-based generation synthesis approach], likelihoods of [static feature] parameters and [dynamic feature] parameters corresponds to the target costs and concatenation costs, respectively. \n",
      " It is easy to understand, if we approximate each state output distribution by a discrete distribution or instances of frame samples in the cluster : when the [dynamic feature] is calculated as the difference between neighboring [static features], the ML-based generation results in a frame-wise DP search like [unit selection]. \n",
      " Thus [HMM-based parameter generation] can be viewed as an analogue version of [unit selection]. \n",
      "\n",
      " [Hybrid approaches] \n",
      "\n",
      " As a natural consequence of the above viewpoints, there are also [hybrid approaches]. \n",
      " Some of these approaches use [spectrum parameters], F 0 values, and durations (or a part of them) generated from HMM to calculate acoustic target costs for [unit selection]. \n",
      " Similarly, HMM likelihoods are used as “ costs ” for [unit selection]. \n",
      " Among of these approaches, use frame-sized units, and use generated longer trajectories to provide “ costs ” for [unit selection]. \n",
      " Another type of [hybrid approaches] uses [statistical models] as a probabilistic smoother for [unit selection]. \n",
      " Unifying [unit selection] and [HMM-based generation synthesis] is also investigated. \n",
      " In the future, we may converge at an optimal form of corpusbased [speech synthesis] fusing generation and selection approaches. \n",
      "\n",
      " CONCLUSION \n",
      "\n",
      " We can see that [statistical parametric speech synthesis] offers a wide range of techniques to improve spoken output. \n",
      " Its more complex models, when compared to standard [unit selection], allow for general solutions, without necessarily requiring recording [speech] in all [phonetic] and prosodic contexts. \n",
      " The pure [unit selection] view requires very [large databases] to cover examples of all desired prosodic, [phonetic] and stylistic variation. \n",
      " In contrast [statistical parametric synthesis] allows for models to be combined and adapted thus not requiring instances of all possible combinations of contexts. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__== \"__main__\":\n",
    "    \"\"\"Main -> to modify by putting all steps in one fonction\"\"\"\n",
    "    init_data = read_data('lexicon.tsv')\n",
    "    data = select_data(init_data)\n",
    "    text_dataframe = lemma_posttag('tts-articles/txt/21.txt')\n",
    "#     text_dataframe = lemma_posttag('test2.txt')\n",
    "#     print(text_dataframe.head(60))\n",
    "    text_dataframe.to_csv(r'terms.txt', header=None, index=None, sep=' ', mode='w')\n",
    "    annotate(data, text_dataframe)\n",
    "    print(construct_annotated_text(text_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
