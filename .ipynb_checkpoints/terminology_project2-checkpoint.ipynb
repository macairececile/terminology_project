{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology - Project\n",
    "Authors: Cécile MACAIRE & Ludivine ROBERT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "import re\n",
    "import string as s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from lexicon\n",
    "def read_data(file):\n",
    "    \"\"\"Read data file with pandas dataframe\"\"\"\n",
    "    return pd.read_csv(file, sep='\\t')\n",
    "\n",
    "def select_data(dataframe):\n",
    "    \"\"\"Lemmatization of lexicon with scapy\"\"\"\n",
    "    terms = dataframe['pilot']\n",
    "    lemma = []\n",
    "    for el in terms:\n",
    "        doc = spacy_nlp(el.lower())\n",
    "        tmp = [token.lemma_ for token in doc]\n",
    "        lemma = [l.replace(' - ', '-') for l in lemma]\n",
    "        lemma.append(' '.join(tmp))\n",
    "    df = pd.DataFrame({'pattern':dataframe['pattern'], 'pilot':dataframe['pilot'], 'lemma':lemma})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text\n",
    "def read_file(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return f.read()\n",
    "        \n",
    "def lemma_posttag(file):\n",
    "    \"\"\"Convert post-tag scapy into corresponding pattern from lexicon\"\"\"\n",
    "    text = read_file(file)\n",
    "    doc_a = spacy_nlp(text)\n",
    "    doc = spacy_nlp(text.lower())\n",
    "    new_pos = []\n",
    "    pos = []\n",
    "    lemma = []\n",
    "    t = []\n",
    "    original = [token.text for token in doc_a]\n",
    "    for token in doc:\n",
    "        t.append(token.text)\n",
    "        lemma.append(token.lemma_)\n",
    "        pos.append(token.pos_)\n",
    "        if token.pos_ == 'NOUN' or token.pos_ == 'PROPN':\n",
    "            new_pos.append('N')\n",
    "        elif token.pos_ == 'VERB':\n",
    "            new_pos.append('V')\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            new_pos.append('A')\n",
    "        elif token.pos_ == 'CCONJ' or token.pos_ == 'SCONJ':\n",
    "            new_pos.append('C')\n",
    "        elif token.pos_ == 'PART' or token.pos_ == 'ADP':\n",
    "            new_pos.append('P')\n",
    "        else:\n",
    "            new_pos.append('')\n",
    "#     print(len(original))\n",
    "#     print(len(lemma))\n",
    "#     print(len(t))\n",
    "#     print(len(pos))\n",
    "#     print(len(new_pos))\n",
    "    frame = pd.DataFrame({'tokens': original,'tokens_lower':t, 'lemma':lemma, 'pos':pos, 'pattern':new_pos})\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_adj = ['acoustic', 'accented', 'artificial', 'attentional', 'autoregressive', 'bidirectional', 'bilingual', 'cross-lingual', 'fluent',\n",
    "            'gated', 'generated', 'intelligible', 'labelled', 'phonetic', 'monolingual', 'multilingual', 'multispeaker', 'neural',\n",
    "            'substantial', 'supervised', 'training', 'unlabelled', 'unsupervised']\n",
    "def rules(terms_dataframe, text_dataframe):\n",
    "    \"\"\"Define rules from terms according to their pattern\"\"\"\n",
    "    new_terms = []\n",
    "    for terms in terms_dataframe['lemma']:\n",
    "        # Get the same structure of terms as in text dataframe\n",
    "        tmp = ' '.join(terms.split('-'))\n",
    "        new_terms.append(tmp.split(' '))\n",
    "    for i, token in enumerate(text_dataframe['lemma']):\n",
    "        for j, t in enumerate(new_terms):\n",
    "            # Case 1: term of size 3 seperated by dashes (ex: text-to-speech) and followed by 1, 2 Nouns or 1 Adj and 1 Noun is a term \n",
    "            if len(t) == 3 and len(text_dataframe['lemma']) >= i+5:\n",
    "                if token == t[0] and text_dataframe['lemma'][i+1] == '-' and (text_dataframe['lemma'][i+2] == 'to' or text_dataframe['lemma'][i+2] == 'of' or text_dataframe['lemma'][i+2] == 'by' or text_dataframe['pattern'][i+2] == 'N') and text_dataframe['lemma'][i+3] == '-' and text_dataframe['lemma'][i+4] == t[2]:\n",
    "                    # followed by 2 nouns (ex: text-to-speech modal synthesis)\n",
    "                    if (text_dataframe['pattern'][i+5] == 'N' or text_dataframe['pattern'][i+4] == 'A') and text_dataframe['pattern'][i+6] == 'N':\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+6] = text_dataframe['tokens'][i+6]+']'                        \n",
    "                    elif text_dataframe['pattern'][i+5] == 'N':\n",
    "                        # followed by 1 noun (ex: text-to-speech system)\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+5] = text_dataframe['tokens'][i+5]+']'\n",
    "                    else:\n",
    "                        text_dataframe['tokens'][i] = '[' + text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i + 4] = text_dataframe['tokens'][i + 4] + ']'\n",
    "            # Case 2: term of size 2 separated by dashes (ex: encoder-decoder) and followed by 0,1,2 or 3 nouns is a term\n",
    "            elif len(t) >= 2 and len(text_dataframe['lemma']) >= i+3 and i != 0:\n",
    "                if token == 'front' and text_dataframe['lemma'][i+1] == '-' and text_dataframe['lemma'][i+2] == 'end':\n",
    "                    if text_dataframe['pattern'][i-1] == 'N':\n",
    "                        text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]\n",
    "                        text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "                if token == t[0] and text_dataframe['lemma'][i+1] == '-' and text_dataframe['lemma'][i+2] == t[1]:\n",
    "                    # followed by 3 nouns (ex: HMM-based generation synthesis approach)\n",
    "                    if text_dataframe['pattern'][i+3] == 'N' and text_dataframe['pattern'][i+4] == 'N' and text_dataframe['pattern'][i+5] == 'N':\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+5] = text_dataframe['tokens'][i+5]+']'\n",
    "                    # followed by 2 nouns (ex: HMM-based generation synthesis)\n",
    "                    elif (text_dataframe['pattern'][i+3] == 'N' or text_dataframe['pattern'][i+3] == 'A' or text_dataframe['pattern'][i + 3] == 'V') and text_dataframe['pattern'][i+4] == 'N':\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+4] = text_dataframe['tokens'][i+4]+']'\n",
    "                    # followed by 1 noun (ex: cross-lingual adaptation)\n",
    "                    elif text_dataframe['pattern'][i+3] == 'N':\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+3] = text_dataframe['tokens'][i+3]+']'\n",
    "                    # followed by nothing (ex: mel-spectrogram)\n",
    "                    else:\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "        if (token == 'data' or token == 'voice' or token == 'datum' or token == 'speaker' or token == 'dataset' or token == 'database' or token == 'feature' or token == 'corpus' or token == 'language') and i != 0 and len(text_dataframe['lemma']) >= i+1:\n",
    "            if text_dataframe['pattern'][i-1] == 'N' or text_dataframe['pattern'][i-1] == 'A':\n",
    "                text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]\n",
    "                text_dataframe['tokens'][i] = text_dataframe['tokens'][i]+']'\n",
    "            elif text_dataframe['pattern'][i+1] == 'N':\n",
    "                text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                text_dataframe['tokens'][i+1] = text_dataframe['tokens'][i+1]+']'\n",
    "        if i != 0:\n",
    "            if text_dataframe['lemma'][i-1] in rule_adj and '[' in text_dataframe['tokens'][i]:\n",
    "                text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]+']'\n",
    "            elif i >= 3 and text_dataframe['lemma'][i-1] in rule_adj and text_dataframe['lemma'][i-3] == 'non' and '[' in text_dataframe['tokens'][i]:\n",
    "                    text_dataframe['tokens'][i-3] = '['+text_dataframe['tokens'][i-3]\n",
    "                    text_dataframe['tokens'][i-3] = text_dataframe['tokens'][i-1] + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_4 = ['accent', 'accuracy', 'activation', 'adaptation', 'algorithm', 'alignment', 'approach', \n",
    "          'architecture', 'attribute', 'boundary', 'cell', 'class', 'classifier', 'cluster', 'component', \n",
    "          'concatenation', 'content', 'contour', 'control', 'conversion', 'coverage', 'detection', \n",
    "          'detection', 'device', 'dictionary', 'embedding', 'encoding', 'engineering', 'entry', 'error', \n",
    "          'evaluation', 'experiment', 'expertise', 'file', 'filter', 'form', 'framework', 'function', \n",
    "          'generation', 'identification', 'implementation', 'improvement', 'inference', 'input', 'kernel', 'layer', 'learning', \n",
    "          'length', 'location', 'mapping', 'method', 'model', 'module', 'naturalness', 'network', \n",
    "          'nonlinearity', 'optimization', 'output', 'pair', 'parameter', 'pipeline', 'posterior', 'prediction', \n",
    "          'process', 'processing', 'quality', 'realization', 'recognition', 'representation', 'research', \n",
    "          'result', 'sample', 'score', 'sequence', 'set', 'setting', 'signal', 'string', 'study', 'symbol', \n",
    "          'synthesis', 'synthesizer', 'system', 'task', 'technique', 'technique', 'technology', 'token', 'tool', \n",
    "          'toolkit', 'training', 'transcription', 'transfer', 'transform', 'translation', 'value', 'generator',\n",
    "          'corpora', 'tilt', 'knowledge', 'category', 'track', 'tagger', 'unit', 'label']\n",
    "def annotate(terms_dataframe, text_dataframe):\n",
    "    \"\"\"Annotate the terms of the text thanks to list of terms + applied rules\"\"\"\n",
    "    rules(terms_dataframe, text_dataframe)  # apply rules\n",
    "    for i, token in enumerate(text_dataframe['lemma']):\n",
    "        for term in terms_dataframe['lemma']:\n",
    "            term = term.split(' ')\n",
    "            # Case 1: if terms of length 4, we check if each word from text corresponds to each word in the term\n",
    "            if len(term) == 4:\n",
    "                term_1 = term[0]\n",
    "                if token == term_1 and len(text_dataframe['lemma']) >= i+4:\n",
    "                    if text_dataframe['lemma'][i+1] == term[1] and text_dataframe['lemma'][i+2] == term[2] and text_dataframe['lemma'][i+3] == term[3]:\n",
    "                        if text_dataframe['lemma'][i+4] in rule_4:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+4] = text_dataframe['tokens'][i+4]+']'\n",
    "                        else:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+3] = text_dataframe['tokens'][i+3]+']'\n",
    "            # Case 2: terms of length 3\n",
    "            elif len(term) == 3:\n",
    "                term_1 = term[0]\n",
    "                if token == term_1 and len(text_dataframe['lemma']) > i+3:\n",
    "                    if text_dataframe['lemma'][i+1] == term[1] and text_dataframe['lemma'][i+2] == term[2]:\n",
    "                        if text_dataframe['lemma'][i+3] in rule_4:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+3] = text_dataframe['tokens'][i+3]+']'\n",
    "                        else:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "            # Case 3: terms of length 2\n",
    "            elif len(term) == 2:\n",
    "                if token == term[0] and len(text_dataframe['lemma']) > i+2:\n",
    "                    if text_dataframe['lemma'][i+1] == term[1]:\n",
    "                        if text_dataframe['lemma'][i+2] in rule_4:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "                        else:\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+1] = text_dataframe['tokens'][i+1]+']'\n",
    "            # Case 4: term of length 1\n",
    "            elif token == term[0] and i > 1 and text_dataframe['lemma'][i-1] == 'of' and text_dataframe['lemma'][i-2] == 'sequence':\n",
    "                text_dataframe['tokens'][i-2] = '['+text_dataframe['tokens'][i-2]\n",
    "                text_dataframe['tokens'][i] = text_dataframe['tokens'][i]+']'\n",
    "            elif token == term[0] and len(term) == 1 and len(text_dataframe['lemma']) >= i+2 and text_dataframe['lemma'][i+1] == ')':\n",
    "                if text_dataframe['lemma'][i+2] in rule_4:\n",
    "                    text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]\n",
    "                    text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "                else:\n",
    "                    text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]+']'\n",
    "            elif token == term[0] and len(term) == 1 and len(text_dataframe['lemma']) >= i+1:\n",
    "                if text_dataframe['lemma'][i+1] in rule_4:\n",
    "                    text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                    text_dataframe['tokens'][i+1] = text_dataframe['tokens'][i+1]+']'\n",
    "                else:\n",
    "                    text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]+']'\n",
    "        if i != 0:\n",
    "            if text_dataframe['lemma'][i-1] in rule_adj and '[' in text_dataframe['tokens'][i]:\n",
    "                text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]+']'\n",
    "            elif i >= 3 and text_dataframe['lemma'][i-1] in rule_adj and text_dataframe['lemma'][i-3] == 'non' and '[' in text_dataframe['tokens'][i]:\n",
    "                text_dataframe['tokens'][i-3] = '['+text_dataframe['tokens'][i-3]\n",
    "                text_dataframe['tokens'][i-3] = text_dataframe['tokens'][i-1] + ']'\n",
    "    return text_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_annotated_text(text_dataframe):\n",
    "    \"\"\"Return the text from the annotated text dataframe with the correct annotation of brackets\"\"\"\n",
    "    content = ' '.join(text_dataframe['tokens'].to_list())\n",
    "    compt = 0\n",
    "    compt2 = 0\n",
    "    string = ''\n",
    "    for i in content:\n",
    "        if i == '[':\n",
    "            if compt == 0:\n",
    "                compt += 1\n",
    "                string += i\n",
    "            elif compt >= 1:\n",
    "                compt += 1\n",
    "        elif i == ']':\n",
    "            if compt-1 != compt2:\n",
    "                compt2 += 1\n",
    "            else:\n",
    "                string += i\n",
    "                compt = 0\n",
    "                compt2 = 0\n",
    "        else:\n",
    "            string += i\n",
    "    string2 = ''\n",
    "    string = string.replace('] [', ' ')\n",
    "    string = string.replace(' .', '.')\n",
    "    string = string.replace(' ’', '’')\n",
    "    string = string.replace(' ,', ',')\n",
    "    string = string.replace(' - ', '-')\n",
    "    string = string.replace('( ', '(')\n",
    "    string = string.replace(' )', ')')\n",
    "    string = string.replace(']-[', '-')\n",
    "    string = string.replace('.]', '].')\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging_IOB(string):\n",
    "    \"\"\"Tagging the terms into IOB and POS\"\"\"\n",
    "    is_term = False \n",
    "    string_tag = string.split(' ')\n",
    "    annotated = []\n",
    "    for k,l in enumerate(string_tag):\n",
    "        if '[' in l and ']' in l:\n",
    "            for i,j in enumerate(l):\n",
    "                if l[i] == ']':\n",
    "                    annotated.append(l[:i]+ ' (B)]'+l[i+1:])\n",
    "        else:\n",
    "            if '[' in l and is_term is False:\n",
    "                annotated.append(l+ ' (B)')\n",
    "                is_term = True\n",
    "            elif is_term and ']' not in l:\n",
    "                annotated.append(l+ ' (I)')\n",
    "            elif is_term and ']' in l:\n",
    "                for m,n in enumerate(l):\n",
    "                    if l[m] == ']':\n",
    "                        annotated.append(l[:m]+ ' (I)]'+l[m+1:])\n",
    "                is_term = False\n",
    "            else:\n",
    "                if \"\\n\" not in l and l != 0 and l not in s.punctuation:\n",
    "                    annotated.append(l+ ' (O)')\n",
    "                else:\n",
    "                    annotated.append(l)\n",
    "    iob_string = ' '.join(annotated)\n",
    "#    print(iob_string)\n",
    "    return iob_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def POS_tags(string):\n",
    "    tagged = []\n",
    "    doc = spacy_nlp(string)\n",
    "    for el in doc:\n",
    "        if el.text not in ['B','O','I','\\n'] and el.text not in s.punctuation and len(el.text) != 0:\n",
    "            tagged.append(el.text+' '+el.pos_)\n",
    "        else:\n",
    "            tagged.append(el.text)\n",
    "    all_tags = ' '.join(tagged)\n",
    "    all_tags = all_tags.replace('( ', '(')\n",
    "    all_tags = all_tags.replace(' )', ')')\n",
    "    all_tags = all_tags.replace('[ ', '[')\n",
    "    all_tags = all_tags.replace(' ]', ']')\n",
    "    all_tags = all_tags.replace('SPACE','')\n",
    "#    print(all_tags)\n",
    "    return all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TUNDRA PROPN (B)] : A NOUN (O) [Multilingual ADJ (B) Corpus PROPN (I)] of ADP (O) Found VERB (O) Data NOUN (O) for ADP (O) [TTS PROPN (B) Research PROPN (I)] Created VERB (O) with ADP (O) [Light NOUN (B) Supervision PROPN (I)] \n",
      "\n",
      "   Abstract PROPN (O)        \n",
      "   [Simple4All PROPN (B) Tundra PROPN (I)] (version NOUN (O) 1.0 NUM) (O) is AUX (O) the DET (O) first ADV (O) release NOUN (O) of ADP (O) a NOUN (O) standardised VERB (O) [multilingual ADJ (B) corpus NOUN (I)] designed VERB (O) for ADP (O) [text NOUN - to ADP - speech NOUN (B) research NOUN (I)] with ADP (O) imperfect NOUN (O) or CCONJ (O) found VERB (O) data NOUN . (O) \n",
      "   The DET (O) corpus NOUN (O) consists VERB (O) of ADP (O) approximately ADV (O) 60 NUM (O) hours NOUN (O) of ADP (O) [speech NOUN (B) data NOUN (I)] from ADP (O) audiobooks NOUN (O) in ADP (O) 14 NUM (O) languages NOUN , (O) as SCONJ (O) well INTJ (O) as SCONJ (O) [utterance NOUN - level NOUN (B) alignments NOUN (I)] obtained VERB (O) with ADP (O) a NOUN (O) lightly ADV - supervised VERB (O) process NOUN . (O) \n",
      "   Future NOUN (O) versions NOUN (O) of ADP (O) the DET (O) corpus NOUN (O) will NOUN (O) include VERB (O) finer NOUN - grained VERB (O) alignment NOUN (O) and CCONJ (O) prosodic NOUN (O) annotation NOUN , (O) all DET (O) of ADP (O) which DET (O) will NOUN (O) be AUX (O) made VERB (O) freely ADV (O) available ADJ . (O) \n",
      "   This DET (O) paper NOUN (O) gives VERB (O) a NOUN (O) general NOUN (O) outline NOUN (O) of ADP (O) the DET (O) data NOUN (O) collected VERB (O) so CCONJ (O) far ADV , (O) as SCONJ (O) well INTJ (O) as SCONJ (O) a NOUN (O) detailed ADJ (O) description NOUN (O) of ADP (O) how ADV (O) this DET (O) has AUX (O) been AUX (O) done VERB , (O) emphasizing NOUN (O) the DET (O) [minimal ADJ (B) language NOUN - specific ADJ (I) knowledge NOUN (I)] and CCONJ (O) manual NOUN (O) intervention NOUN (O) used VERB (O) to ADP (O) compile NOUN (O) the DET (O) corpus X . (O) \n",
      "   To ADP (O) demonstrate NOUN (O) its DET (O) potential NOUN (O) use NOUN , (O) [text NOUN - to ADP - speech NOUN (B) systems NOUN (I)] have AUX (O) been AUX (O) built VERB (O) for ADP (O) all DET (O) languages NOUN (O) using VERB (O) unsupervised VERB (O) or CCONJ (O) [lightly ADV (B) supervised VERB (I) methods NOUN (I)] , also ADV (O) briefly INTJ (O) presented VERB (O) in ADP (O) the DET (O) paper NOUN . (O) \n",
      "   Index PROPN (O) Terms NOUN (O) : [multilingual ADJ (B) corpus NOUN (I)] , [light NOUN (B) supervision NOUN (I)] , [imperfect NOUN (B) data NOUN (I)] , found VERB (O) data NOUN , (O) [text NOUN - to ADP - speech NOUN (B)] , [audiobook PROPN (B) data NOUN (I)] \n",
      "\n",
      "   Introduction NOUN (O) \n",
      "   Building PROPN (O) a NOUN (O) [text NOUN - to ADP - speech NOUN (B) (TTS PROPN) (I) conversion NOUN (I) system NOUN (I)] for ADP (O) a NOUN (O) [new ADJ (B) language NOUN (I)] has AUX (O) in ADP (O) the DET (O) past NOUN (O) been AUX (O) an DET (O) expensive ADJ (O) and CCONJ (O) time NOUN - consuming VERB (O) activity NOUN . (O) \n",
      "   Using VERB (O) data NOUN - driven VERB (O) methods NOUN (O) to ADP (O) build VERB , (O) for ADP (O) example NOUN , (O) a NOUN (O) [statistical ADJ (B) parametric NOUN (I) waveform VERB (I) generation NOUN (I)] module NOUN (O) or CCONJ (O) [TTS PROPN (B) back NOUN - end NOUN (I)] , can VERB (O) alleviate NOUN (O) to ADP (O) some DET (O) extent NOUN (O) the DET (O) lack NOUN (O) of ADP (O) expert NOUN (O) [linguistic ADJ (B) knowledge NOUN (I)] . \n",
      "   Even ADV (O) then ADV , (O) however ADV , (O) a NOUN (O) recording NOUN (O) script NOUN (O) must VERB (O) be AUX (O) prepared VERB , (O) a NOUN (O) [voice NOUN (B) talent NOUN (I)] recruited VERB (O) and CCONJ (O) high ADJ - quality NOUN (O) [speech NOUN (B) recording NOUN (I)] carefully ADV (O) supervised VERB . (O) \n",
      "   Also ADV (O) problematic ADJ (O) is AUX (O) the DET (O) text NOUN - processing NOUN (O) component NOUN (O) of ADP (O) the DET (O) system NOUN , (O) i.e. X (O) the DET (O) [TTS PROPN (B) front ADJ - end NOUN (I)] , if SCONJ (O) none NOUN (O) is AUX (O) available ADJ (O) for ADP (O) the DET (O) [target NOUN (B) language NOUN (I)] . \n",
      "   A NOUN (O) [front NOUN - end NOUN (B)] is AUX (O) made VERB (O) up ADP (O) of ADP (O) [rule NOUN - based VERB (B)] or CCONJ (O) statistical ADJ (O) modules NOUN (O) ; acquiring VERB (O) the DET (O) expert NOUN (O) knowledge NOUN (O) required VERB (O) either CCONJ (O) to ADP (O) manually ADV (O) specify NOUN (O) those DET (O) rules NOUN , (O) or CCONJ (O) to ADP (O) annotate NOUN (O) a NOUN (O) learning NOUN (O) sample NOUN (O) on ADP (O) which DET (O) to ADP (O) train NOUN (O) the DET (O) [statistical ADJ (B) models NOUN (I)] , represents VERB (O) a NOUN (O) major ADJ (O) obstacle NOUN (O) to ADP (O) creating VERB (O) a NOUN (O) [TTS PROPN (B) system NOUN (I)] for ADP (O) a NOUN (O) new ADJ (O) [target NOUN (B) language NOUN (I)] and CCONJ (O) requires VERB (O) highly ADV (O) specialised ADJ (O) knowledge NOUN . (O) \n",
      "   Such ADJ (O) non ADJ - trivial ADJ (O) tasks NOUN (O) include VERB , (O) for ADP (O) example NOUN , (O) specifying VERB (O) a NOUN (O) [phoneme NOUN - set NOUN (B)] or CCONJ (O) [part NOUN (B) of ADP (I) speech NOUN (I)] (POS PROPN) (O) [tag NOUN - set NOUN (B)] for ADP (O) a NOUN (O) language NOUN (O) where ADV (O) one NUM (O) has AUX (O) not PART (O) already ADV (O) been AUX (O) defined VERB (O) ; annotating VERB (O) plain NOUN (O) text NOUN (O) with ADP (O) [POS PROPN (B) tags NOUN (I)] , as SCONJ (O) required VERB (O) to ADP (O) train NOUN (O) a NOUN (O) [POS PROPN (B) tagger NOUN (I)] and CCONJ (O) annotating VERB (O) the DET (O) surface NOUN (O) forms NOUN (O) of ADP (O) words NOUN (O) with ADP (O) [phonemes NOUN (B)] to ADP (O) build VERB (O) a NOUN (O) [pronunciation NOUN (B) lexicon NOUN (I)] . \n",
      "   One NUM (O) of ADP (O) the DET (O) primary ADJ (O) goals NOUN (O) of ADP (O) the DET (O) project NOUN (O) Simple4All1 PROPN (O) is AUX (O) to ADP (O) produce NOUN (O) freely ADV (O) available ADJ (O) tools NOUN (O) for ADP (O) building NOUN (O) [TTS PROPN (B) systems NOUN (I)] with ADP (O) little ADJ (O) or CCONJ (O) no INTJ (O) expert NOUN (O) supervision NOUN (O) from ADP (O) freely ADV (O) available ADJ (O) existing VERB (O) data NOUN . (O) \n",
      "   These DET (O) tools NOUN (O) enable VERB (O) us PRON (O) to ADP (O) sidestep NOUN (O) the DET (O) expense NOUN (O) associated VERB (O) with ADP (O) engineering NOUN (O) a NOUN (O) [speech NOUN (B) corpus NOUN (I)] in ADP (O) each DET (O) new ADJ (O) [target NOUN (B) language NOUN (I)] from ADP (O) scratch NOUN , (O) in ADP (O) the DET (O) case NOUN (O) where ADV (O) data NOUN (O) is AUX (O) not PART (O) readily ADV (O) available ADJ . (O) \n",
      "   Our DET (O) [toolkit NOUN (B)] includes VERB (O) modules NOUN (O) for ADP (O) handling NOUN (O) imperfect NOUN (O) recording NOUN (O) conditions NOUN , (O) segmenting NOUN (O) [audio NOUN (B)] into ADP (O) manageable ADJ (O) chunks NOUN , (O) and CCONJ (O) aligning VERB (O) those DET (O) chunks NOUN (O) with ADP (O) a NOUN (O) chapter NOUN (O) or CCONJ (O) book NOUN - level NOUN (O) text NOUN (O) transcription NOUN . (O) \n",
      "   We PRON (O) here ADV (O) explain VERB (O) how ADV (O) these DET (O) tools NOUN (O) have AUX (O) been AUX (O) applied VERB (O) to ADP (O) existing VERB (O) [audiobook NOUN (B) data NOUN (I)] in ADP (O) 14 NUM (O) languages NOUN , (O) most ADJ (O) of ADP (O) it PRON (O) freely ADV (O) available ADJ , (O) to ADP (O) create VERB (O) a NOUN (O) [multilingual ADJ (B) corpus NOUN (I)] with ADP (O) minimal ADJ (O) manual NOUN (O) intervention NOUN (O) and CCONJ (O) [language NOUN - specific ADJ (B) expert NOUN (I) knowledge NOUN (I)] . \n",
      "   The DET (O) result NOUN (O) of ADP (O) this DET (O) processing NOUN (O) is AUX (O) a NOUN (O) standardised VERB (O) [multilingual NOUN (B) database NOUN (I)] of ADP (O) ‘ PUNCT (O) found VERB ’ PUNCT (O) data NOUN , (O) which DET (O) we PRON (O) release NOUN (O) under ADP (O) the DET (O) name NOUN (O) [Tundra PROPN (B)] . \n",
      "   There ADV (O) has AUX (O) been AUX (O) much ADJ (O) recent ADJ (O) interest NOUN (O) in ADP (O) in ADP (O) using VERB (O) found VERB (O) data NOUN (O) to ADP (O) produce NOUN (O) [TTS PROPN (B) systems NOUN (I)] , in ADP (O) particular ADJ , (O) [speech NOUN (B) data NOUN (I)] from ADP (O) audiobook NOUN (O) recordings NOUN . (O) \n",
      "   We PRON (O) note NOUN (O) that SCONJ (O) the DET (O) [Arctic PROPN (B) databases VERB (I)] have AUX (O) provided VERB (O) a NOUN (O) valuable ADJ (O) resource NOUN (O) for ADP (O) research NOUN (O) into ADP (O) [TTS PROPN (B)] using VERB (O) conventional ADJ (O) purpose NOUN - recorded VERB (O) databases NOUN , (O) in ADP (O) that SCONJ (O) they PRON (O) are AUX (O) freely ADV (O) available ADJ (O) and CCONJ (O) serve VERB (O) as SCONJ (O) a NOUN (O) common ADJ (O) point NOUN (O) of ADP (O) reference NOUN (O) for ADP (O) benchmarking NOUN . (O) \n",
      "   In ADP (O) view NOUN (O) of ADP (O) this DET (O) significant ADJ (O) and CCONJ (O) growing VERB (O) interest NOUN (O) in ADP (O) building NOUN (O) [TTS PROPN (B) systems NOUN (I)] from ADP (O) found VERB (O) data NOUN , (O) we PRON (O) feel VERB (O) there ADV (O) is AUX (O) a NOUN (O) need NOUN (O) for ADP (O) a NOUN (O) similarly ADV (O) standardised VERB (O) and CCONJ (O) freely-[available PROPN (B) corpus NOUN (I)] of ADP (O) found VERB (O) data NOUN . (O) We PRON (O) present ADJ (O) [Tundra PROPN (B)] to ADP (O) the DET (O) [TTS PROPN (B)] researchommunity NOUN (O) in ADP (O) the DET (O) hope NOUN (O) that SCONJ (O) it PRON (O) can NOUN (O) start VERB (O) to ADP (O) fill NOUN (O) that SCONJ (O) need NOUN . (O) \n",
      "   Our DET (O) [toolkit NOUN (B)] also ADV (O) includes VERB (O) modules NOUN (O) for ADP (O) selecting VERB (O) a NOUN (O) subset NOUN (O) of ADP (O) utterances NOUN (O) with ADP (O) a NOUN (O) uniform NOUN (O) speaking VERB (O) style NOUN , (O) and CCONJ (O) constructing VERB (O) [TTS PROPN (B) systems NOUN (I)] from ADP (O) text NOUN (O) and CCONJ (O) [speech NOUN (B) data NOUN (I)] without ADP (O) reliance NOUN (O) on ADP (O) [language NOUN - specific ADJ (B) expert NOUN (I) knowledge NOUN (I)] or CCONJ (O) on ADP (O) conventional ADJ (O) linguistic ADJ (O) resources NOUN (O) such ADJ (O) as SCONJ (O) [lexicons NOUN (B)] , phonesets NOUN , (O) [part NOUN - of ADP - speech NOUN (B) taggersetc NOUN (I)] . \n",
      "   In ADP (O) order NOUN (O) to ADP (O) show NOUN (O) that SCONJ (O) it PRON (O) is AUX (O) feasible ADJ (O) to ADP (O) build VERB (O) voices NOUN (O) on ADP (O) corpora NOUN (O) built VERB (O) with ADP (O) such ADJ (O) minimal ADJ (O) expert NOUN (O) supervision NOUN , (O) we PRON (O) also ADV (O) present ADJ (O) a NOUN (O) demonstration NOUN (O) of ADP (O) [TTS PROPN (B) systems NOUN (I)] that DET (O) we PRON (O) have AUX (O) built VERB (O) by ADP (O) applying VERB (O) these DET (O) tools NOUN (O) to ADP (O) [Tundra PROPN (B)] . \n",
      "   We PRON (O) do AUX (O) not PART (O) present ADJ (O) detailed ADJ (O) explanation NOUN , (O) evaluation NOUN (O) and CCONJ (O) analysis NOUN (O) of ADP (O) these DET (O) demo NOUN (O) systems NOUN (O) here ADV (O) due ADJ (O) to ADP (O) space NOUN (O) limitations NOUN , (O) and CCONJ (O) refer NOUN (O) interested ADJ (O) readers NOUN (O) to PART , (O) where ADV (O) such ADJ (O) details NOUN (O) will NOUN (O) be AUX (O) given VERB . (O) \n",
      "   An NOUN (O) initial ADJ (O) public NOUN (O) version NOUN (O) of ADP (O) the DET (O) [Simple4All PROPN (B) tools NOUN (I)] used VERB (O) to ADP (O) compile NOUN (O) the DET (O) corpus NOUN (O) and CCONJ (O) build VERB (O) the DET (O) [demo NOUN (B) voices NOUN (I)] is AUX (O) due ADJ (O) to ADP (O) be AUX (O) released VERB (O) in ADP (O) November PROPN (O) 2013 NUM . (O) \n",
      "\n",
      "   www.simple4all.org/ NOUN (O)    \n",
      "\n",
      "   [Corpus PROPN (B) Construction PROPN (I)] \n",
      "   In ADP (O) this DET (O) section NOUN (O) we PRON (O) describe VERB (O) the DET (O) pipeline NOUN (O) of ADP (O) [data NOUN (B) processing NOUN (I)] involved VERB (O) in ADP (O) building NOUN (O) the DET (O) [Tundra PROPN (B) corpus NOUN (I)] , from ADP (O) [speech NOUN (B)] denoisingand NOUN (O) deverberation NOUN (O) to ADP (O) [lightly ADV (B) supervised VERB (I) speech NOUN (I)] and CCONJ (O) text NOUN (O) alignment NOUN . (O) \n",
      "   All DET (O) the DET (O) steps NOUN (O) presented VERB (O) in ADP (O) the DET (O) following VERB (O) subsections NOUN (O) are AUX (O) based VERB (O) solely ADV (O) on ADP (O) found VERB (O) [speech NOUN (B)] and CCONJ (O) text NOUN (O) resources NOUN (O) and CCONJ (O) could VERB (O) be AUX (O) easily ADV (O) applied VERB (O) to ADP (O) any DET (O) other ADJ (O) resource NOUN , (O) even ADV (O) by ADP (O) non ADJ - expert ADJ (O) users NOUN . (O) \n",
      "   As SCONJ (O) regards NOUN (O) [language NOUN (B) dependency NOUN (I)] , the DET (O) only ADV (O) step NOUN (O) which DET (O) requires VERB (O) familiarity NOUN (O) with ADP (O) at ADP (O) least ADJ (O) the DET (O) script NOUN (O) of ADP (O) the DET (O) [target NOUN (B) language NOUN (I)] is AUX (O) the DET (O) first ADV (O) step NOUN (O) of ADP (O) matching NOUN (O) 10 NUM (O) minutes NOUN (O) of ADP (O) [speech NOUN (B)] with ADP (O) an DET (O) orthographic ADJ (O) transcript NOUN . (O) \n",
      "   All DET (O) the DET (O) other ADJ (O) processes NOUN (O) can NOUN (O) be AUX (O) performed VERB (O) by ADP (O) the DET (O) users NOUN (O) with ADP (O) little ADJ (O) or CCONJ (O) no INTJ (O) training NOUN (O) in ADP (O) [speech NOUN (B) processing NOUN (I)] and CCONJ (O) without ADP (O) relying VERB (O) on ADP (O) any DET (O) [target NOUN (B) language NOUN (I) knowledge NOUN (I)] . \n",
      "\n",
      "   [Speech PROPN (B)] Pre ADJ - processing NOUN (O) \n",
      "   Conventional PROPN (O) [TTS PROPN (B) corpora NOUN (I)] deliver VERB (O) [speech NOUN (B)] recorded VERB (O) in ADP (O) noise NOUN - free ADJ (O) non ADJ - reverberant ADJ (O) environments NOUN , (O) and CCONJ (O) thus ADV (O) lead NOUN (O) to ADP (O) high ADJ - quality NOUN (O) [synthetic ADJ (B) speech NOUN (I)] . \n",
      "   Found VERB (O) data NOUN , (O) on ADP (O) the DET (O) other ADJ (O) hand NOUN (O) are AUX (O) usually ADV (O) recorded VERB (O) in ADP (O) sub NOUN - optimal ADJ (O) conditions NOUN , (O) and CCONJ (O) without ADP (O) professional ADJ (O) recording NOUN (O) equipment NOUN . (O) \n",
      "   Therefore ADV , (O) when ADV (O) building NOUN (O) [TTS PROPN (B) systems NOUN (I)] on ADP (O) this DET (O) type NOUN (O) of ADP (O) data NOUN , (O) some DET (O) pre NOUN - processing NOUN (O) steps NOUN (O) are AUX (O) in ADP (O) order NOUN . (O) \n",
      "   For ADP (O) [Tundra PROPN (B)] , recordings NOUN (O) which DET (O) casual ADJ (O) listening NOUN (O) suggested VERB (O) were AUX (O) sub NOUN - optimal ADJ (O) went VERB (O) through ADP (O) the DET (O) following VERB (O) pre NOUN - processing NOUN (O) steps NOUN , (O) applied VERB (O) to ADP (O) each DET (O) recording NOUN (O) session NOUN (O) individually,2 VERB (O) so CCONJ (O) that SCONJ (O) variations NOUN (O) in ADP (O) between ADP (O) them PRON (O) can NOUN (O) be AUX (O) normalised ADJ (O) : \n",
      "   Noise PROPN (O) reduction NOUN (O) : uses NOUN (O) a NOUN (O) multi ADJ - band ADJ (O) noise NOUN (O) gate NOUN (O) removal NOUN (O) with ADP (O) a NOUN (O) 20dB NUM (O) noise NOUN (O) reduction NOUN (O) threshold NOUN , (O) a NOUN (O) frequency NOUN (O) smoothing VERB (O) of ADP (O) 150 NUM (O) Hz PROPN (O) and CCONJ (O) 0.15 NUM (O) second ADJ (O) decay NOUN (O) time NOUN . (O) \n",
      "   The DET (O) noise NOUN (O) profile NOUN (O) was AUX (O) selected VERB (O) from ADP (O) the DET (O) initial ADJ (O) silence NOUN (O) segments NOUN (O) of ADP (O) each DET (O) [speech NOUN (B) file NOUN (I)] . \n",
      "   Normalisation NOUN (O) : DC PROPN (O) offset NOUN (O) was AUX (O) removed VERB , (O) and CCONJ (O) the DET (O) recordings NOUN (O) were AUX (O) normalised ADJ (O) to ADP (O) a NOUN (O) maximum NOUN (O) amplitude NOUN (O) of ADP (O) -0.1 PUNCT (O) dB NOUN , (O) so CCONJ (O) that SCONJ (O) the DET (O) average NOUN (O) energy NOUN (O) level NOUN (O) is AUX (O) the DET (O) same ADJ (O) across ADP (O) different ADJ (O) recording NOUN (O) sessions NOUN . (O) \n",
      "   Deverberation PROPN (O) : was AUX (O) performed VERB (O) using VERB (O) a NOUN (O) RMS PROPN (O) based VERB (O) algorithm INTJ , (O) with ADP (O) a NOUN (O) smoothing VERB (O) of ADP (O) 40 NUM (O) ms NOUN (O) and CCONJ (O) a NOUN (O) release NOUN (O) of ADP (O) 400ms ADJ . (O) \n",
      "\n",
      "   [Lightly ADV - supervised VERB (B) Audio PROPN (I) Segmentation NOUN (I)] \n",
      "   Current NOUN (O) [parametric NOUN (B) TTS PROPN (I) systems NOUN (I)] generally ADV (O) use NOUN (O) [training NOUN (B) data NOUN (I)] which DET (O) is AUX (O) segmented VERB (O) into ADP (O) sentence NOUN - length NOUN (O) chunks NOUN , (O) and CCONJ (O) rarely ADV (O) make VERB (O) use NOUN (O) of ADP (O) contexts NOUN (O) beyond ADP (O) the DET (O) current ADJ (O) sentence NOUN . (O) \n",
      "   The DET (O) small ADJ (O) length NOUN (O) of ADP (O) the DET (O) [training NOUN (B) data NOUN (I)] is AUX (O) also ADV (O) a NOUN (O) limitation NOUN (O) of ADP (O) the DET (O) forced VERB (O) alignment NOUN (O) algorithm NOUN (O) while SCONJ (O) training NOUN . (O) \n",
      "   Although SCONJ (O) several ADJ (O) algorithms NOUN (O) have AUX (O) been AUX (O) proposed VERB (O) to ADP (O) enable VERB (O) the DET (O) use NOUN (O) of ADP (O) longer ADJ (O) [speech NOUN (B)] segments NOUN , (O) we PRON (O) still ADV (O) consider VERB (O) that SCONJ (O) sentence NOUN - length NOUN (O) utterances NOUN (O) are AUX (O) the DET (O) building NOUN (O) blocks NOUN (O) of ADP (O) [TTS PROPN (B)] , and CCONJ (O) longer ADJ (O) segments NOUN (O) can NOUN (O) be AUX (O) easily ADV (O) obtained VERB (O) by ADP (O) concatenating VERB (O) the DET (O) former ADJ , (O) thus ADV (O) ensuring VERB (O) a NOUN (O) paragraph NOUN (O) or CCONJ (O) maybe ADV (O) chapter NOUN (O) level NOUN (O) analysis NOUN (O) or CCONJ (O) training NOUN . (O) \n",
      "   presents NOUN (O) a NOUN (O) [lightly ADV (B) supervised VERB (I) method NOUN (I)] for ADP (O) the DET (O) segmentation NOUN (O) of ADP (O) [speech NOUN (B)] into ADP (O) sentences NOUN . (O) The DET (O) method NOUN (O) uses NOUN (O) a NOUN (O) small ADJ (O) amount NOUN (O) of ADP (O) manually ADV (O) labelled VERB (O) data NOUN , (O) in ADP (O) which DET (O) the DET (O) silence NOUN (O) between ADP (O) sentences NOUN (O) is AUX (O) marked VERB (O) for ADP (O) around ADV (O) 5 NUM (O) to ADP (O) 10 NUM (O) minutes NOUN (O) of ADP (O) [speech NOUN (B)] . \n",
      "   Silence PROPN (O) marking VERB (O) is AUX (O) a NOUN (O) trivial NOUN (O) task NOUN (O) and CCONJ (O) requires VERB (O) no INTJ (O) technical ADJ (O) knowledge NOUN . (O) \n",
      "   Using VERB (O) the DET (O) initial ADJ (O) [training NOUN (B) data NOUN (I)] , standard ADJ (O) [Gaussian PROPN (B)] mixture NOUN (O) models NOUN (O) (GMMs PROPN) (O) with ADP (O) 16 NUM (O) components NOUN (O) are AUX (O) trained VERB (O) for ADP (O) [speech NOUN (B)] and CCONJ (O) silence NOUN (O) respectively ADV . (O) \n",
      "   The DET (O) observation NOUN (O) [vectors NOUN (B)] consist VERB (O) of ADP (O) energy NOUN , (O) 12 NUM (O) dimensional ADJ (O) MFCCs NOUN , (O) their DET (O) [delta NOUN (B) features NOUN (I)] , and CCONJ (O) the DET (O) number NOUN (O) of ADP (O) zero NUM (O) crossings NOUN (O) in ADP (O) a NOUN (O) frame NOUN . (O) \n",
      "   The DET (O) distinction NOUN (O) between ADP (O) [speech NOUN (B)] and CCONJ (O) silence NOUN (O) is AUX (O) made VERB (O) by ADP (O) calculating VERB (O) the DET (O) [log NOUN (B) likelihood NOUN (I)] ratio NOUN (O) (LLR PROPN) (O) of ADP (O) each DET (O) frame NOUN . (O) \n",
      "   The DET (O) framewise NOUN (O) LLR PROPN (O) is AUX (O) smoothed VERB (O) using VERB (O) a NOUN (O) moving VERB (O) median NOUN (O) filter NOUN . (O) \n",
      "   While SCONJ (O) doing VERB (O) sentence NOUN (O) level NOUN (O) segmentation NOUN , (O) an DET (O) important ADJ (O) aspect NOUN (O) is AUX (O) to ADP (O) discriminate NOUN (O) between ADP (O) within ADP - sentence NOUN (O) breaks NOUN , (O) and CCONJ (O) sentence NOUN (O) boundary ADJ (O) breaks NOUN . (O) \n",
      "   Therefore ADV , (O) the DET (O) trained VERB (O) GMMs NOUN (O) likelihood NOUN (O) scores NOUN (O) are AUX (O) evaluated VERB (O) on ADP (O) the DET (O) [training NOUN (B) data NOUN (I)] , and CCONJ (O) the DET (O) durations NOUN (O) of ADP (O) the DET (O) sentence NOUN (O) boundary ADJ (O) silence NOUN (O) segments NOUN (O) and CCONJ (O) the DET (O) durations NOUN (O) of ADP (O) within ADP - sentence NOUN (O) silence NOUN (O) segments NOUN (O) are AUX (O) computed VERB . (O) \n",
      "   Two NUM (O) [Gaussian PROPN (B)] PDFs NOUN (O) are AUX (O) then ADV (O) fitted VERB (O) to ADP (O) the DET (O) two NUM (O) model NOUN (O) durations NOUN . (O) \n",
      "   The DET (O) intersection NOUN (O) point NOUN (O) of ADP (O) the DET (O) two NUM (O) PDFs NOUN (O) is AUX (O) used VERB (O) as SCONJ (O) a NOUN (O) duration NOUN (O) threshold NOUN (O) to ADP (O) classify NOUN (O) silent ADJ (O) segments NOUN (O) as SCONJ (O) either CCONJ (O) sentence NOUN - internal ADJ (O) or CCONJ (O) sentence NOUN (O) boundary ADJ (O) breaks NOUN . (O) \n",
      "   Results NOUN (O) presented VERB (O) in ADP (O) showed VERB (O) that SCONJ (O) this DET (O) method NOUN (O) when ADV (O) applied VERB (O) to ADP (O) an DET (O) English PROPN (O) audiobook NOUN , (O) successfully ADV (O) identified VERB (O) most ADJ (O) of ADP (O) the DET (O) sentence NOUN (O) boundaries NOUN . (O) \n",
      "   We PRON (O) also ADV (O) evaluate VERB (O) it PRON (O) in ADP (O) this DET (O) paper NOUN (O) by ADP (O) comparing VERB (O) [speech NOUN (B)]-based ADJ segmentation NOUN (O) results NOUN (O) against ADP (O) the DET (O) text NOUN (O) based VERB (O) ones NOUN . (O) \n",
      "\n",
      "   Audiobooks NOUN (O) are AUX (O) usually ADV (O) distributed VERB (O) in ADP (O) chapter NOUN - size NOUN (O) chunks NOUN (O) which DET (O) correspond NOUN (O) to ADP (O) one NUM (O) recording NOUN (O) session NOUN . (O) \n",
      "\n",
      "   [Lightly ADV - supervised VERB (B) Speech PROPN (I)] and CCONJ (O) Text NOUN (O) Alignment PROPN (O) \n",
      "   In ADP (O)     we PRON (O) first ADV (O) introduced VERB (O) a NOUN (O) method NOUN (O) for ADP (O) the DET (O) automatic ADJ (O) alignment NOUN (O) of ADP (O) [speech NOUN (B) data NOUN (I)] with ADP (O) unsynchronised ADJ , (O) imperfect NOUN (O) transcripts NOUN , (O) for ADP (O) a NOUN (O) domain NOUN (O) where ADV (O) no INTJ (O) initial ADJ (O) [acoustic ADJ (B) models NOUN (I)] are AUX (O) available ADJ . (O) \n",
      "   As SCONJ (O) opposed VERB (O) to PART , (O) where ADV (O) existing VERB (O) high ADJ - quality NOUN (O) acoustic ADJ (O) and CCONJ (O) [language NOUN (B) models NOUN (I)] are AUX (O) used VERB , (O) our DET (O) method NOUN (O) requires VERB (O) only ADV (O) relatively ADV (O) low ADJ - quality NOUN (O) [grapheme NOUN - based VERB (B) acoustic ADJ (I) models NOUN (I)] trained VERB (O) solely ADV (O) on ADP (O) the DET (O) [speech NOUN (B)] resource NOUN (O) to ADP (O) be AUX (O) aligned VERB . (O) \n",
      "   To ADP (O) overcome NOUN (O) the DET (O) lack NOUN (O) of ADP (O) good ADJ (O) [acoustic ADJ (B) models NOUN (I)] , the DET (O) [ASR PROPN (B)] decoding VERB (O) network NOUN (O) is AUX (O) limited VERB (O) to ADP (O) a NOUN (O) sequence NOUN (O) of ADP (O) words NOUN (O) derived VERB (O) from ADP (O) the DET (O) approximate ADJ (O) transcript NOUN , (O) similar ADJ (O) to PART . (O) \n",
      "   This DET (O) sequence NOUN (O) is AUX (O) called VERB (O) a NOUN (O) skip NOUN (O) network NOUN . (O) \n",
      "   The DET (O) confidence NOUN (O) of ADP (O) the DET (O) alignment NOUN (O) is AUX (O) ranked VERB (O) based VERB (O) on ADP (O) the DET (O) acoustic ADJ (O) scores NOUN (O) obtained VERB (O) in ADP (O) the DET (O) decoding VERB (O) process NOUN (O) with ADP (O) different ADJ (O) degrees NOUN (O) of ADP (O) freedom NOUN (O) included VERB (O) in ADP (O) the DET (O) skip NOUN (O) network NOUN . (O) \n",
      "   Manual PROPN (O) intervention NOUN (O) is AUX (O) limited VERB (O) to ADP (O) matching NOUN (O) the DET (O) first ADV (O) 10 NUM (O) minutes NOUN (O) of ADP (O) [speech NOUN (B)] with ADP (O) the DET (O) correct ADJ (O) text NOUN (O) transcription NOUN , (O) to ADP (O) provide VERB (O) data NOUN (O) for ADP (O) training NOUN (O) the DET (O) initial ADJ (O) [acoustic ADJ (B) models NOUN (I)] , similar ADJ (O) to PART . (O) \n",
      "   This DET (O) feature NOUN (O) makes VERB (O) the DET (O) method NOUN (O) easily ADV (O) applicable ADJ (O) in ADP (O) any DET (O) language NOUN (O) employing VERB (O) an DET (O) alphabetic ADJ (O) writing NOUN (O) system NOUN , (O) and CCONJ (O) enables NOUN (O) the DET (O) use NOUN (O) of ADP (O) found VERB (O) data NOUN (O) without ADP (O) the DET (O) hassle NOUN (O) of ADP (O) manually ADV (O) transcribing NOUN (O) its DET (O) entirety NOUN . (O) \n",
      "   Initial PROPN (O) results NOUN (O) on ADP (O) the DET (O) English PROPN (O) audiobook NOUN (O) A NOUN (O) Tramp PROPN (O) Abroad ADV (O) by ADP (O) Mark PROPN (O) Twain3 PROPN (O) showed VERB (O) an DET (O) average NOUN (O) 55 NUM (O) % [confident ADJ (B) data NOUN (I)] , with ADP (O) a NOUN (O) [WER PROPN (B)] of ADP (O) 1 NUM (O) % and CCONJ (O) SER PROPN (O) of ADP (O) 8 NUM (O) % . (O) \n",
      "   Since SCONJ (O) then ADV , (O) the DET (O) [acoustic ADJ (B) model NOUN (I) training NOUN (I)] has AUX (O) been AUX (O) extended ADJ (O) to ADP (O) [tri PROPN - grapheme NOUN (B)] and CCONJ (O) [lightly ADV (B) supervised VERB (I)] discriminative ADJ (O) training NOUN , (O) which DET (O) led VERB (O) to ADP (O) an DET (O) average NOUN (O) of75 NOUN (O) % [confident ADJ (B) data NOUN (I)] with ADP (O) similar ADJ (O) word NOUN (O) and CCONJ (O) sentence NOUN (O) error NOUN (O) rates NOUN . (O) \n",
      "   One NUM (O) major ADJ (O) loss NOUN (O) in ADP (O) sentence NOUN (O) accuracy NOUN (O) rates NOUN (O) is AUX (O) due ADJ (O) to ADP (O) utterance NOUN (O) initial ADJ (O) and CCONJ (O) final ADJ (O) word NOUN (O) deletions NOUN (O) and CCONJ (O) insertions NOUN , (O) which DET (O) can VERB (O) not PART (O) be AUX (O) correctly ADV (O) detected VERB (O) by ADP (O) the DET (O) current ADJ (O) confidence NOUN (O) measure NOUN . (O) However ADV , (O) previous ADJ (O) studies NOUN (O) showed VERB (O) that SCONJ (O) phone NOUN (O) errors NOUN (O) less ADJ (O) than SCONJ (O) 1 NUM (O) % do AUX (O) not PART (O) degrade NOUN (O) the DET (O) quality NOUN (O) of ADP (O) the DET (O) [synthetic ADJ (B) speech NOUN (I)] . \n",
      "   The DET (O) output NOUN (O) of ADP (O) the DET (O) alignment NOUN (O) process NOUN (O) is AUX (O) a NOUN (O) set NOUN (O) of ADP (O) segmented VERB (O) [speech NOUN (B) files NOUN (I)] with ADP (O) their DET (O) corresponding ADJ (O) orthographic ADJ (O) transcripts NOUN , (O) including VERB (O) punctuation NOUN , (O) and CCONJ (O) also ADV (O) a NOUN (O) time NOUN (O) alignment NOUN (O) of ADP (O) the DET (O) segments NOUN (O) within ADP (O) the DET (O) initial ADJ (O) [speech NOUN (B) data NOUN (I)] . \n",
      "\n",
      "   The DET (O) Corpus PROPN (O) \n",
      "   The DET (O) procedures NOUN (O) described VERB (O) above ADP (O) have AUX (O) been AUX (O) applied VERB (O) to ADP (O) a NOUN (O) number NOUN (O) of ADP (O) freely ADV (O) available ADJ (O) found VERB (O) resources NOUN . (O) \n",
      "   Audiobooks NOUN (O) were AUX (O) a NOUN (O) first ADV (O) choice NOUN , (O) as SCONJ (O) they PRON (O) are AUX (O) a NOUN (O) readily ADV (O) available ADJ (O) in ADP (O) [multiple NOUN (B) languages NOUN (I)] and CCONJ (O) are AUX (O) generally ADV (O) read NOUN (O) by ADP (O) a NOUN (O) [single ADJ (B) speaker NOUN (I)] and CCONJ (O) recorded VERB (O) with ADP (O) equipment NOUN (O) of ADP (O) at ADP (O) least ADJ (O) reasonable ADJ (O) quality NOUN . (O) \n",
      "   Another DET (O) advantage NOUN (O) would VERB (O) be AUX (O) that SCONJ (O) by ADP (O) using VERB (O) cohesive ADJ (O) and CCONJ (O) expressive ADJ (O) [spoken VERB (B) data NOUN (I)] as SCONJ (O) the DET (O) basis NOUN (O) for ADP (O) training NOUN (O) a NOUN (O) [TTS PROPN (B) system NOUN (I)] might VERB (O) yield NOUN (O) more ADJ (O) cohesive ADJ (O) and CCONJ (O) expressive ADJ (O) multi ADJ - utterance ADJ (O) [TTS PROPN (B) output NOUN (I)] , fact NOUN (O) which DET (O) explains VERB (O) the DET (O) high ADJ (O) interest NOUN (O) in ADP (O) them PRON (O) lately ADV . (O) \n",
      "   This DET (O) latter ADJ (O) advantage NOUN (O) is AUX (O) not PART (O) especially ADV (O) made VERB (O) use NOUN (O) of ADP (O) in ADP (O) the DET (O) [demo NOUN (B) voices NOUN (I)] presented VERB (O) here ADV , (O) but CCONJ (O) is AUX (O) the DET (O) subject NOUN (O) of ADP (O) on ADV - going NOUN (O) work NOUN (O) for ADP (O) us PRON (O) elsewhere ADV . (O) \n",
      "   To ADP (O) emphasise NOUN (O) the DET (O) utility NOUN (O) of ADP (O) audiobooks NOUN (O) in ADP (O) [TTS PROPN (B)] systems NOUN , (O) in ADP (O) Fig NOUN . (O)     we PRON (O) present ADJ (O) a NOUN (O) comparison NOUN (O) between ADP (O) standard NOUN (O) [TTS PROPN (B) corpora NOUN (I)] and CCONJ (O) audiobooks NOUN (O) with ADP (O) respect NOUN (O) to ADP (O) logF0 X (O) in ADP (O) 4 NUM (O) [different ADJ (B) languages NOUN (I)] . \n",
      "   The DET (O) standard NOUN (O) [TTS PROPN (B) corpora NOUN (I)] are AUX (O) : a X (O) subset NOUN (O) of ADP (O) the DET (O) database NOUN (O) called VERB (O) ‘ PUNCT (O) Nina PROPN ’ PUNCT (O) in ADP , (O) a NOUN (O) subset NOUN (O) of ADP (O) a NOUN (O) corpus NOUN (O) of ADP (O) Finnish PROPN (O) [speech NOUN (B)] recorded VERB (O) from ADP (O) a NOUN (O) [female NOUN (B) speaker NOUN (I)] specifically ADV (O) for ADP (O) [TTS PROPN (B)] purposes NOUN , (O) SEV PROPN (O) neutral ADJ (O) and CCONJ (O) RSS PROPN . (O) \n",
      "\n",
      "   http://librivox.org/a-tramp-abroad-by-mark-twain/ NOUN (O) \n",
      "\n",
      "\n",
      "   Table NOUN (O) : [Simple4All PROPN (B) Tundra PROPN (I) Corpus PROPN (I)] overview NOUN (O) \n",
      "\n",
      "   Figure PROPN (O) : logF0 X (O) comparison NOUN (O) of ADP (O) conventional ADJ (O) [TTS PROPN (B) corpora NOUN (I)] versus X (O) [audiobook NOUN (B) data NOUN (I)] in ADP (O) four NUM (O) languages NOUN (O) : English PROPN (O) (EN NOUN) , (O) Spanish PROPN (O) (ES NOUN) , (O) Finnish PROPN (O) (FI PROPN) (O) and CCONJ (O) Romanian PROPN (O) (RM PROPN) . (O) \n",
      "   A NOUN (O) denotes NOUN (O) the DET (O) [audiobook NOUN (B) data NOUN (I)] , and CCONJ (O) S NOUN (O) denotes NOUN (O) the DET (O) standard NOUN (O) [TTS PROPN (B) database NOUN (I)] . \n",
      "   The DET (O) standard NOUN (O) [corpora NOUN (B) speaker NOUN (I)] genders NOUN (O) are AUX (O) the DET (O) same ADJ (O) as SCONJ (O) the DET (O) selected VERB (O) audiobooks NOUN . (O) \n",
      "\n",
      "   Figure PROPN (O) : logF0 X (O) boxplots NOUN (O) for ADP (O) all DET (O) languages NOUN . (O) [Language NOUN (B) codes NOUN (I)] are AUX (O) given VERB (O) in ADP (O) Table NOUN (O) \n",
      "\n",
      "   It PRON (O) can NOUN (O) be AUX (O) easily ADV (O) observed VERB (O) that SCONJ (O) the DET (O) audiobooks NOUN (O) have AUX (O) a NOUN (O) greater ADJ (O) standard NOUN (O) deviation NOUN (O) compared VERB (O) with ADP (O) conventional ADJ (O) corpora NOUN , (O) which DET (O) means VERB (O) that SCONJ (O) they PRON (O) could VERB (O) easily ADV (O) provide VERB (O) a NOUN (O) much ADJ (O) richer ADJ (O) prosodic NOUN (O) context NOUN . (O) \n",
      "   This DET (O) aspect NOUN (O) can NOUN (O) also ADV (O) be AUX (O) noticed VERB (O) from ADP (O) Fig NOUN . (O) where ADV (O) logF0 X (O) distributions NOUN (O) are AUX (O) plotted VERB (O) for ADP (O) all DET (O) the DET (O) languages NOUN (O) of ADP (O) the DET (O) corpus X . (O) \n",
      "   As SCONJ (O) a NOUN (O) result NOUN , (O) [Tundra PROPN (B)] 1.0 NUM (O) includes VERB (O) 14 NUM (O) audiobooks NOUN (O) in ADP (O) 14 NUM (O) languages NOUN (O) : Bulgarian VERB , (O) Danish PROPN , (O) Dutch PROPN , (O) English PROPN , (O) Finnish PROPN , (O) French PROPN , (O) German PROPN , (O) Hungarian PROPN , (O) Italian PROPN , (O) Polish PROPN , (O) Portuguese PROPN , (O) Romanian PROPN , (O) Russian PROPN (O) and CCONJ (O) Spanish PROPN . (O) \n",
      "   [Language NOUN (B) selection NOUN (I)] was AUX (O) based VERB (O) on ADP (O) the DET (O) availability NOUN (O) of ADP (O) both CCONJ (O) [speech NOUN (B) and CCONJ (I) text NOUN (I) data NOUN (I)] , as SCONJ (O) well INTJ (O) as SCONJ (O) the DET (O) language NOUN (O) having VERB (O) an DET (O) alphabetic ADJ (O) writing NOUN (O) system NOUN (O) (in ADP (O) this DET (O) case NOUN , (O) Latin PROPN (O) and CCONJ (O) Cyrillic NOUN (O) alphabets NOUN) . (O) \n",
      "   Important ADJ (O) resources NOUN (O) for ADP (O) these DET (O) are AUX (O) the DET (O) Librivox PROPN (O) and CCONJ (O) Gutenberg4 PROPN (O) projects NOUN , (O) which DET (O) are AUX (O) the DET (O) sources NOUN (O) for ADP (O) most ADJ (O) of ADP (O) the DET (O) data NOUN (O) used VERB (O) to ADP (O) compile NOUN (O) [Tundra PROPN (B)] . \n",
      "   The DET (O) complete ADJ (O) list NOUN (O) [speech NOUN (B)] and CCONJ (O) text NOUN (O) sources NOUN (O) can NOUN (O) be AUX (O) found VERB (O) here ADV (O) http://tundra.simple4all.org/. NOUN (O) \n",
      "\n",
      "   http://librivox.org PROPN (O) and CCONJ (O) http://gutenberg.org/ NOUN (O) \n",
      "\n",
      "   Table NOUN (O) presents NOUN (O) an DET (O) overview NOUN (O) of ADP (O) the DET (O) [entire ADJ (B) corpus NOUN (I)] , including VERB (O) title NOUN (O) and CCONJ (O) author NOUN (O) of ADP (O) the DET (O) audiobook NOUN , (O) [speaker NOUN (B) gender NOUN (I)] and CCONJ (O) total NOUN (O) duration NOUN . (O) \n",
      "   There ADV (O) are AUX (O) 8 NUM (O) male NOUN (O) and CCONJ (O) 6 NUM (O) [female NOUN (B) speakers NOUN (I)] , and CCONJ (O) the DET (O) aligned VERB (O) corpus NOUN (O) amounts NOUN (O) to ADP (O) approximately ADV (O) 60 NUM (O) hours NOUN (O) of ADP (O) [speech NOUN (B)] . \n",
      "   For ADP (O) the DET (O) final ADJ (O) set NOUN (O) of ADP (O) utterances NOUN (O) included VERB (O) in ADP (O) this DET (O) corpus NOUN , (O) each DET (O) audiobook NOUN (O) underwent VERB (O) the DET (O) steps NOUN (O) described VERB (O) in ADP (O) the DET (O) Section NOUN (O) and CCONJ (O) which DET (O) are AUX (O) schematically ADV (O) depicted VERB (O) in ADP (O) Fig NOUN . (O) \n",
      "   Audiobook PROPN (O) chapters NOUN (O) were AUX (O) converted VERB (O) from ADP (O) mp3 NOUN (O) to ADP (O) wav PROPN (O) format NOUN (O) and CCONJ (O) then ADV (O) cleaned VERB (O) if SCONJ (O) the DET (O) overall NOUN (O) quality NOUN (O) was AUX (O) considered VERB (O) low ADJ . (O) \n",
      "   The DET (O) first ADV (O) 10 NUM (O) minutes NOUN (O) of ADP (O) [speech NOUN (B)] were AUX (O) then ADV (O) annotated VERB (O) with ADP (O) silence NOUN (O) segments NOUN (O) and CCONJ (O) manually ADV (O) transcribed PROPN . (O) \n",
      "   Manual PROPN (O) transcription NOUN (O) proved VERB (O) to ADP (O) be AUX (O) a NOUN (O) trivial NOUN (O) task NOUN , (O) and CCONJ (O) based VERB (O) on ADP (O) the DET (O) book NOUN (O) text NOUN , (O) the DET (O) authors NOUN (O) were AUX (O) able ADJ (O) to ADP (O) perform NOUN (O) it PRON , (O) although SCONJ (O) they PRON (O) do AUX (O) not PART (O) speak VERB (O) most ADJ (O) of ADP (O) the DET (O) languages NOUN (O) included VERB (O) in ADP (O) the DET (O) corpus X . (O) \n",
      "   For ADP (O) the DET (O) Cyrillic NOUN (O) writing NOUN (O) [system NOUN (B) languages NOUN (I)] (i.e. X (O) Bulgarian PROPN (O) and CCONJ (O) Russian PROPN) , (O) [native ADJ (B) speakers NOUN (I)] were AUX (O) asked VERB (O) to ADP (O) correct ADJ (O) an DET (O) initial ADJ (O) transcription NOUN (O) provided VERB (O) by ADP (O) the DET (O) authors NOUN . (O) \n",
      "   Data PROPN (O) was AUX (O) then ADV (O) segmented VERB (O) using VERB (O) the DET (O) VAD PROPN (O) algorithm INTJ , (O) and CCONJ (O) the DET (O) resulting VERB (O) number NOUN (O) of ADP (O) [speech NOUN (B)] utterances NOUN (O) is AUX (O) presented VERB (O) in ADP (O) Table NOUN (O) alongside ADP (O) the DET (O) text NOUN - based VERB (O) segmentation NOUN . (O) \n",
      "\n",
      "   For ADP (O) example NOUN , (O) the DET (O) Spanish PROPN (O) and CCONJ (O) [Romanian PROPN (B) data NOUN (I)] are AUX (O) professional ADJ (O) recordings NOUN (O) which DET (O) did AUX (O) not PART (O) require VERB (O) any DET (O) pre NOUN - processing NOUN . (O) \n",
      "   We PRON (O) currently ADV (O) decide VERB (O) whether SCONJ (O) to ADP (O) pre NOUN - process NOUN (O) recordings NOUN (O) based VERB (O) on ADP (O) informal ADJ (O) listening NOUN , (O) but CCONJ (O) aim NOUN (O) to ADP (O) automate NOUN (O) this DET (O) with ADP (O) an DET (O) objective NOUN (O) measure NOUN (O) of ADP (O) [speech NOUN (B) quality NOUN (I)] in ADP (O) future NOUN (O) versions NOUN (O) of ADP (O) our DET (O) [toolkit NOUN (B)] .               \n",
      "\n",
      "   The DET (O) difference NOUN (O) between ADP (O) the DET (O) number NOUN (O) of ADP (O) VAD PROPN (O) and CCONJ (O) text NOUN (O) utterances NOUN (O) results NOUN (O) from ADP (O) the DET (O) writing NOUN (O) style NOUN (O) of ADP (O) the DET (O) book NOUN (O) (i.e. X (O) mostly ADV (O) dialogue NOUN , (O) or CCONJ (O) mostly ADV (O) descriptive ADJ) (O) and CCONJ (O) the DET (O) fact NOUN (O) that SCONJ (O) in ADP (O) the DET (O) alignment NOUN (O) process NOUN , (O) in ADP (O) order NOUN (O) to ADP (O) obtain NOUN (O) the DET (O) [most ADJ (B) data NOUN (I)] from ADP (O) the DET (O) audiobook NOUN , (O) segmented VERB (O) utterances NOUN (O) which DET (O) are AUX (O) shorter ADJ (O) than SCONJ (O) a NOUN (O) specified VERB (O) threshold NOUN (O) (5 NUM (O) seconds NOUN (O) for ADP (O) these DET (O) data NOUN) (O) are AUX (O) concatenated VERB . (O) \n",
      "   After ADP (O) the DET (O) alignment NOUN (O) process NOUN , (O) an DET (O) average NOUN (O) of ADP (O) 68 NUM (O) % of ADP (O) the DET (O) data NOUN (O) were AUX (O) considered VERB (O) confident ADJ (O) and CCONJ (O) included VERB (O) in ADP (O) the DET (O) [final ADJ (B) corpus NOUN (I)] . \n",
      "   Table NOUN (O)     presents NOUN (O) the DET (O) duration NOUN (O) of ADP (O) the DET (O) aligned VERB (O) data NOUN (O) and CCONJ (O) its DET (O) percentage NOUN (O) from ADP (O) the DET (O) total NOUN (O) duration NOUN . (O) This DET (O) percentage NOUN (O) appears VERB (O) to ADP (O) be AUX (O) highly ADV (O) dependent ADJ (O) on ADP (O) : \n",
      "   a X) (O) the DET (O) total NOUN (O) amount NOUN (O) of ADP (O) data NOUN (O) available ADJ (O) : see VERB (O) the DET (O) low ADJ (O) percentage NOUN (O) of ADP (O) the DET (O) Danish PROPN (O) audiobook NOUN (O) which DET (O) has AUX (O) only ADV (O) 2.1 NUM (O) hours NOUN (O) ; \n",
      "   b PROPN) (O) [speaker NOUN (B) gender NOUN (I)] : [female NOUN (B) voices NOUN (I)] seem VERB (O) to ADP (O) have AUX (O) a NOUN (O) lower ADJ (O) alignment NOUN (O) percentage NOUN (O) ; \n",
      "   c PROPN) (O) [grapheme NOUN - to ADP - phoneme NOUN (B) language NOUN (I) complexity NOUN (I)] : see VERB (O) English PROPN (O) and CCONJ (O) French PROPN (O) versus X (O) Italian PROPN (O) and CCONJ (O) German PROPN (O) ; \n",
      "   and CCONJ (O) d NOUN) (O) [speaker NOUN (B) characteristics NOUN (I)] : speaking VERB (O) rhythm NOUN , (O) degree NOUN (O) of ADP (O) expresivity NOUN , (O) as SCONJ (O) well INTJ (O) as SCONJ (O) [general NOUN (B) voice NOUN (I)] quality NOUN (O) also ADV (O) affect NOUN (O) the DET (O) results NOUN . (O) \n",
      "   SER PROPN (O) and CCONJ (O) [WER PROPN (B) values NOUN (I)] for ADP (O) the DET (O) aligned VERB (O) audiobooks NOUN (O) could VERB (O) not PART (O) be AUX (O) exactly ADV (O) determined VERB , (O) as SCONJ (O) this DET (O) would VERB (O) have AUX (O) required VERB (O) their DET (O) full ADJ (O) manual NOUN (O) transcription NOUN , (O) which DET (O) is AUX (O) outside ADV (O) the DET (O) scope NOUN (O) of ADP (O) this DET (O) [corpus NOUN (B) building NOUN (I)] procedure NOUN . (O) \n",
      "   However ADV , (O) one NUM (O) chapter NOUN (O) from ADP (O) each DET (O) audiobook NOUN (O) in ADP (O) the DET (O) languages NOUN (O) spoken VERB (O) by ADP (O) the DET (O) authors NOUN (O) was AUX (O) evaluated VERB , (O) and CCONJ (O) the DET (O) errors NOUN (O) tend VERB (O) to ADP (O) be AUX (O) similar ADJ (O) to ADP (O) those DET (O) in ADP , (O) meaning NOUN (O) a NOUN (O) less ADJ (O) than SCONJ (O) 1 NUM (O) % [WER PROPN (B)] and CCONJ (O) a NOUN (O) 8 NUM (O) % SER NOUN . (O) \n",
      "   Higher ADJ (O) error NOUN (O) rates NOUN (O) were AUX (O) reported VERB (O) for ADP (O) the DET (O) noisier ADJ (O) [speech NOUN (B) data NOUN (I)] (see VERB (O) Table NOUN (O) for ADP (O) general NOUN (O) signal NOUN - to ADP - noise NOUN (O) ratios NOUN) . (O) \n",
      "   To ADP (O) be AUX (O) useful ADJ (O) as SCONJ (O) a NOUN (O) standardised VERB (O) [TTS PROPN (B) corpus NOUN (I)] , [Tundra PROPN (B)] is AUX (O) also ADV (O) partitioned VERB (O) into ADP (O) training NOUN (O) and CCONJ (O) test NOUN (O) sets NOUN . (O) \n",
      "   To ADP (O) ensure VERB (O) a NOUN (O) satisfactory ADJ (O) amount NOUN (O) of ADP (O) testing NOUN (O) data NOUN (O) even ADV (O) for ADP (O) the DET (O) shortest NOUN (O) audiobook NOUN , (O) the DET (O) [test NOUN (B) data NOUN (I)] were AUX (O) selected VERB (O) from ADP (O) the DET (O) final ADJ (O) chapters NOUN (O) / parts NOUN (O) of ADP (O) the DET (O) audiobooks NOUN , (O) so CCONJ (O) that SCONJ (O) they PRON (O) amount NOUN (O) to ADP (O) at ADP (O) least ADJ (O) 10 NUM (O) % of ADP (O) the DET (O) aligned VERB (O) duration NOUN (O) of ADP (O) it PRON . (O) \n",
      "   The DET (O) entire ADJ (O) segmented VERB (O) and CCONJ (O) aligned VERB (O) corpus NOUN , (O) along ADP (O) with ADP (O) the DET (O) chapter NOUN - wise ADJ (O) time NOUN (O) alignment NOUN (O) and CCONJ (O) training NOUN (O) / test NOUN (O) set NOUN (O) division NOUN (O) of ADP (O) can NOUN (O) be AUX (O) downloaded VERB (O) from ADP (O) http://tundra.simple4all.org NOUN (O) \n",
      "\n",
      "   Spanish PROPN (O) and CCONJ (O) Romanian PROPN (O) also ADV (O) have AUX (O) very ADV (O) simple ADJ (O) [G2P PROPN (B)] rules NOUN , (O) but CCONJ (O) the DET (O) speakers NOUN ’ PUNCT (O) greater ADJ (O) expressivity NOUN (O) limits NOUN (O) the DET (O) alignner NOUN ’s PUNCT (O) performance NOUN . (O) \n",
      "   This DET (O) being AUX (O) a NOUN (O) subjective ADJ (O) measure NOUN , (O) we PRON (O) encourage VERB (O) readers NOUN (O) to ADP (O) listen VERB (O) to ADP (O) samples NOUN (O) of ADP (O) the DET (O) audiobooks NOUN . (O) \n",
      "         \n",
      "   Figure NOUN (O) : Outline NOUN (O) of ADP (O) [corpus NOUN (B) construction NOUN (I)] and CCONJ (O) [voice NOUN (B) building NOUN (I)] \n",
      "\n",
      "   Demo PROPN (O) \n",
      "   To ADP (O) show NOUN (O) the DET (O) feasibility NOUN (O) of ADP (O) using VERB (O) a NOUN (O) corpus NOUN (O) that SCONJ (O) has AUX (O) been AUX (O) compiled VERB (O) with ADP (O) such ADJ (O) minimal ADJ (O) intervention NOUN (O) and CCONJ (O) [language NOUN - specific ADJ (B) expertise NOUN (I)] , we PRON (O) have AUX (O) used VERB (O) it PRON (O) to ADP (O) build NOUN (O) demo NOUN (O) [TTS PROPN (B) voices NOUN (I)] in ADP (O) the DET (O) corpuslanguages NOUN . (O) \n",
      "   To ADP (O) build VERB (O) these DET (O) voices NOUN (O) we PRON (O) first ADV (O) select ADJ (O) a NOUN (O) subset NOUN (O) of ADP (O) utterances NOUN (O) spoken VERB (O) in ADP (O) a NOUN (O) homogenous ADJ (O) style NOUN (O) using VERB (O) a NOUN (O) slightly ADV (O) supervised VERB (O) active ADJ (O) learning NOUN - based VERB (O) approach NOUN . (O) \n",
      "   We PRON (O) then ADV (O) employ NOUN (O) a NOUN (O) [toolkit NOUN (B)] which DET (O) has AUX (O) been AUX (O) specifically ADV (O) designed VERB (O) to ADP (O) construct VERB (O) [TTS PROPN (B) front NOUN - ends NOUN (I)] while SCONJ (O) making VERB (O) as SCONJ (O) few ADJ (O) implicit ADJ (O) assumptions NOUN (O) about ADV (O) the DET (O) [target NOUN (B) language NOUN (I)] as SCONJ (O) possible ADJ , (O) and CCONJ (O) to ADP (O) be AUX (O) configurable ADJ (O) with ADP (O) minimal ADJ (O) effort NOUN (O) and CCONJ (O) expert NOUN (O) knowledge NOUN (O) to ADP (O) suit NOUN (O) arbitrary ADJ (O) new ADJ (O) [target NOUN (B) languages NOUN (I)] . \n",
      "   The DET (O) modules NOUN (O) of ADP (O) our DET (O) [toolkit NOUN (B)] therefore ADV (O) rely VERB (O) where ADV (O) possible ADJ (O) on ADP (O) resources NOUN (O) which DET (O) are AUX (O) intended VERB (O) to ADP (O) be AUX (O) universal ADJ . (O) \n",
      "   For ADP (O) example NOUN , (O) to ADP (O) tokenise NOUN (O) input NOUN (O) text NOUN (O) we PRON (O) rely VERB (O) on ADP (O) character NOUN (O) properties NOUN (O) given VERB (O) in ADP (O) the DET (O) Unicode PROPN (O) [character NOUN (B) database NOUN (I)] – PUNCT (O) a NOUN (O) regular ADJ (O) expression NOUN (O) defined VERB (O) over ADP (O) these DET (O) properties NOUN (O) has AUX (O) so CCONJ (O) far ADV (O) produced VERB (O) sensible NOUN (O) tokenisations NOUN (O) in ADP (O) a NOUN (O) variety NOUN (O) of ADP (O) alphabetic ADJ (O) (Latin PROPN - based VERB , (O) Cyrillic PROPN) (O) and CCONJ (O) alphasyllabic NOUN (O) (Brahmic PROPN) (O) scripts NOUN .) (O) \n",
      "   A NOUN (O) [letter NOUN - based VERB (B) approach NOUN (I)] is AUX (O) used VERB , (O) in ADP (O) which DET (O) the DET (O) names NOUN (O) of ADP (O) letters NOUN (O) are AUX (O) used VERB (O) directly ADV (O) as SCONJ (O) the DET (O) names NOUN (O) of ADP (O) [speech NOUN (B)] modelling NOUN (O) units NOUN (O) (in ADP (O) place NOUN (O) of ADP (O) the DET (O) [phonemes NOUN (B)] of ADP (O) a NOUN (O) conventional ADJ (O) [front NOUN - end NOUN (B)]) . \n",
      "   This DET (O) has AUX (O) given VERB (O) good ADJ (O) results NOUN (O) for ADP (O) languages NOUN (O) with ADP (O) transparent NOUN (O) alphabetic ADJ (O) orthographies NOUN (O) such ADJ (O) as SCONJ (O) Romanian PROPN , (O) Spanish PROPN (O) and CCONJ (O) Finnish PROPN , (O) and CCONJ (O) can NOUN (O) give VERB (O) acceptable ADJ (O) results NOUN (O) even ADV (O) for ADP (O) languages NOUN (O) with ADP (O) less ADJ (O) transparent NOUN (O) orthographies NOUN , (O) such ADJ (O) as SCONJ (O) English PROPN . (O) \n",
      "   Furthermore ADV , (O) our DET (O) tools NOUN (O) make VERB (O) no INTJ (O) use NOUN (O) of ADP (O) expert NOUN - specified VERB (O) categories NOUN (O) of ADP (O) letter NOUN (O) and CCONJ (O) word NOUN , (O) such ADJ (O) as SCONJ (O) [phonetic NOUN (B) categories NOUN (I)] (vowel NOUN , (O) nasal NOUN , (O) approximant NOUN , (O) etc X .) (O) and CCONJ (O) [part NOUN (B) of ADP (I) speech NOUN (I) categories NOUN (I)] (noun PROPN , (O) verb NOUN , (O) adjective NOUN , (O) etc X .) . (O) \n",
      "   Instead ADV , (O) we PRON (O) use NOUN (O) features NOUN (O) that SCONJ (O) are AUX (O) designed VERB (O) to ADP (O) stand VERB (O) in ADP (O) for ADP (O) such ADJ (O) expert NOUN (O) knowledge NOUN (O) but CCONJ (O) which DET (O) are AUX (O) derived VERB (O) fully ADV (O) automatically ADV (O) from ADP (O) the DET (O) distributional ADJ (O) analysis NOUN (O) of ADP (O) plain ADJ (O) text NOUN (O) in ADP (O) the DET (O) [target NOUN (B) language NOUN (I)] . \n",
      "   Samples PROPN (O) of ADP (O) the DET (O) voices NOUN (O) can NOUN (O) be AUX (O) heard VERB (O) at ADP (O) http://tundra.simple4all.org/demo/. NOUN (O) \n",
      "   For ADP (O) reasons NOUN (O) of ADP (O) space NOUN (O) we PRON (O) refer NOUN (O) readers NOUN (O) interested ADJ (O) in ADP (O) full ADJ (O) presentation NOUN (O) and CCONJ (O) evaluation NOUN (O) of ADP (O) thesesystems NOUN (O) to PART . (O) \n",
      "\n",
      "   Conclusion PROPN (O) \n",
      "   We PRON (O) have AUX (O) introduced VERB (O) a NOUN (O) first ADV (O) version NOUN (O) of ADP (O) the DET (O) [Simple4All PROPN (B) Tundra PROPN (I) corpus PROPN (I)] , and CCONJ (O) described VERB (O) its DET (O) construction NOUN (O) from ADP (O) readily ADV (O) available ADJ (O) [speech NOUN (B) data NOUN (I)] . \n",
      "   14 NUM (O) audiobooks NOUN (O) in ADP (O) 14 NUM (O) languages NOUN (O) have AUX (O) been AUX (O) so CCONJ (O) far ADV (O) included VERB (O) in ADP (O) the DET (O) corpus NOUN (O) along ADP (O) with ADP (O) their DET (O) orthographic ADJ (O) transcripts NOUN . (O) \n",
      "   [Tundra PROPN (B)] will NOUN (O) be AUX (O) extended ADJ (O) in ADP (O) the DET (O) future NOUN (O) with ADP (O) other ADJ (O) types NOUN (O) of ADP (O) imperfect NOUN , (O) found VERB (O) data NOUN , (O) such ADJ (O) as SCONJ (O) lectures NOUN , (O) or CCONJ (O) parliamentary ADJ (O) [speech NOUN (B)] , data NOUN (O) which DET (O) have AUX (O) a NOUN (O) higher ADJ (O) degree NOUN (O) of ADP (O) spontaneity NOUN (O) and CCONJ (O) expressivity NOUN . (O) \n",
      "   We PRON (O) will NOUN (O) also ADV (O) aim NOUN (O) at ADP (O) making VERB (O) available ADJ (O) finer NOUN - grained VERB (O) alignments NOUN (O) of ADP (O) the DET (O) data NOUN , (O) and CCONJ (O) also ADV (O) more ADJ (O) elaborate NOUN (O) prosodic NOUN (O) annotations NOUN , (O) such ADJ (O) as SCONJ (O) style NOUN (O) diarisation NOUN , (O) emphasis NOUN (O) or CCONJ (O) sentiment NOUN (O) analysis NOUN . (O) \n",
      "   The DET (O) [TTS PROPN (B) systems NOUN (I)] built VERB (O) from ADP (O) this DET (O) corpus NOUN (O) demonstrate NOUN (O) a NOUN (O) first ADJ (O) application NOUN (O) of ADP (O)     the DET (O) [Tundra PROPN (B) corpus NOUN (I)] , and CCONJ (O) support NOUN (O) its DET (O) usefulness NOUN . (O) \n",
      "\n",
      "   Acknowledgements NOUN (O) \n",
      "   The DET (O) research NOUN (O) leading VERB (O) to ADP (O) these DET (O) results NOUN (O) has AUX (O) received VERB (O) funding NOUN (O) from ADP (O) the DET (O) European PROPN (O) Community NOUN ’s PUNCT (O) Seventh ADJ (O) Framework NOUN (O) Programme NOUN (O) (FP7/2007 NUM - 2013 NUM) (O) under ADP (O) grant NOUN (O) agreement NOUN (O) No INTJ (O) 287678 NUM . (O) \n",
      "   The DET (O) research NOUN (O) presented VERB (O) here ADV (O) has AUX (O) made VERB (O) use NOUN (O) of ADP (O) the DET (O) resources NOUN (O) provided VERB (O) by ADP (O) the DET (O) Edinburgh PROPN (O) Compute PROPN (O) and CCONJ (O) [Data NOUN (B) Facility NOUN (I)] (ECDF PROPN (O) : http://www.ecdf.ed.ac.uk PROPN) . (O) \n",
      "   The DET (O) ECDF NOUN (O) is AUX (O) partially ADV (O) supported VERB (O) by ADP (O) the DET (O) eDIKT NOUN (O) initiative NOUN (O) (http://www.edikt.org.uk PROPN) . (O) \n",
      "   We PRON (O) would VERB (O) like INTJ (O) to ADP (O) thank VERB (O) Mihai PROPN (O) Nae PROPN (O) from ADP (O) Cartea PROPN (O) Sonora PROPN (O) for ADP (O) releasing VERB (O) the DET (O) [Romanian PROPN (B) data NOUN (I)] , as SCONJ (O) well INTJ (O) as SCONJ (O) to ADP (O) all DET (O) the DET (O) volunteers NOUN (O) at ADP (O) Librivox PROPN (O) and CCONJ (O) Gutenberg PROPN (O) for ADP (O) dedicating NOUN (O) their DET (O) time NOUN (O) to ADP (O) distribute NOUN (O) this DET (O) wide ADJ (O) variety NOUN (O) of ADP (O) data NOUN . (O)\n"
     ]
    }
   ],
   "source": [
    "if __name__== \"__main__\":\n",
    "    \"\"\"Main -> to modify by putting all steps in one fonction\"\"\"\n",
    "    init_data = read_data('lexicon.tsv')\n",
    "    data = select_data(init_data)\n",
    "    text_dataframe = lemma_posttag('tts-articles/txt/1.txt')\n",
    "#     text_dataframe = lemma_posttag('test2.txt')\n",
    "#     print(text_dataframe.head(60))\n",
    "    text_dataframe.to_csv(r'terms.txt', header=None, index=None, sep=' ', mode='w')\n",
    "    annotate(data, text_dataframe)\n",
    "#     print(construct_annotated_text(text_dataframe))\n",
    "    annotation = construct_annotated_text(text_dataframe)\n",
    "    iob_text = tagging_IOB(annotation)\n",
    "    annotations = POS_tags(iob_text)\n",
    "    print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
